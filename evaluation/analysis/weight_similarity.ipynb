{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a19ac0",
   "metadata": {},
   "source": [
    "# Weight Similarity Between BERT and the Extended V&L Models\n",
    "We first match weight keys between bert and the V&L models.  \n",
    "And then, calculate similarity for each pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175f13bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_vl_glue import transformers_volta\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10df2bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _new_format_rule(weight_keys):\n",
    "    \"\"\"Get a key mapping that converts old format \n",
    "    to new format if needed from a PyTorch state_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = {}\n",
    "    \n",
    "    for key in weight_keys:\n",
    "        new_key = None\n",
    "        if \"gamma\" in key:\n",
    "            new_key = key.replace(\"gamma\", \"weight\")\n",
    "        if \"beta\" in key:\n",
    "            new_key = key.replace(\"beta\", \"bias\")\n",
    "        if new_key:\n",
    "            mapping[key] = new_key\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9e600dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _volta_rule(volta_config, weight_keys):\n",
    "    \"\"\"Get a key mapping that converts layer names of bert \n",
    "    to those of volta using the mapping defined in volta config\n",
    "    \"\"\"\n",
    "    \n",
    "    mapping = {}\n",
    "    \n",
    "    for key in weight_keys:\n",
    "        new_key = None\n",
    "        if \".layer.\" in key:\n",
    "            layer_id = int(key.split(\".layer.\")[-1].split(\".\")[0])\n",
    "            if \".attention.\" in key:\n",
    "                layer_src = layer_id\n",
    "                layer_dest = volta_config.bert_layer2attn_sublayer.get(str(layer_id), layer_id)\n",
    "                new_key = key.replace(f\".layer.{layer_src}.attention.\", f\".layer.{layer_dest}.attention_\")\n",
    "            elif \".intermediate.\" in key:\n",
    "                layer_src = layer_id\n",
    "                layer_dest = volta_config.bert_layer2ff_sublayer.get(str(layer_id), layer_id)\n",
    "                new_key = key.replace(f\".layer.{layer_src}.intermediate.\", f\".layer.{layer_dest}.intermediate.\")\n",
    "            elif \".output.\" in key:\n",
    "                layer_src = layer_id\n",
    "                layer_dest = volta_config.bert_layer2ff_sublayer.get(str(layer_id), layer_id)\n",
    "                new_key = key.replace(f\".layer.{layer_src}.output.\", f\".layer.{layer_dest}.output.\")\n",
    "        if new_key:\n",
    "            mapping[key] = new_key\n",
    "    \n",
    "    return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e63d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_mapping(weight_keys, mapping):\n",
    "    \"\"\"Get a new key list by applying key mapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    new_weight_keys = []\n",
    "    for key in weight_keys:\n",
    "        new_weight_keys.append(mapping.get(key, key))\n",
    "    \n",
    "    return new_weight_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c02b1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight_table(bert_model, volta_model):\n",
    "    \"\"\"Compare the weights between bert_model and volta_model\n",
    "    and get a table on the weight similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get orignal and modiefied key mapping on volta model\n",
    "    volta_state_dict = volta_model.state_dict()\n",
    "    volta_original_keys = list(volta_state_dict.keys())\n",
    "    volta_new_format_rule_mapping = _new_format_rule(volta_original_keys)\n",
    "    volta_keys = _apply_mapping(volta_original_keys, volta_new_format_rule_mapping)\n",
    "    \n",
    "    # Get orignal and modiefied key mapping on bert model\n",
    "    bert_state_dict = bert_model.state_dict()\n",
    "    bert_original_keys = list(bert_state_dict.keys())\n",
    "    bert_new_format_rule_mapping = _new_format_rule(bert_original_keys)\n",
    "    bert_keys = _apply_mapping(bert_original_keys, bert_new_format_rule_mapping)\n",
    "    bert_volta_rule_mapping = _volta_rule(volta_model.config, bert_keys)\n",
    "    bert_keys = _apply_mapping(bert_keys, bert_volta_rule_mapping)\n",
    "    \n",
    "    # Correspond to the original keys by matchning them with the modified keys.\n",
    "    volta_bert_mapping = OrderedDict()\n",
    "    for key, o_key in zip(volta_keys, volta_original_keys):\n",
    "        if key in bert_keys:\n",
    "            i = bert_keys.index(key)\n",
    "            volta_bert_mapping[o_key] = bert_original_keys[i]\n",
    "        else:\n",
    "            volta_bert_mapping[o_key] = None\n",
    "    \n",
    "    # Calculate statistics for each layer\n",
    "    results = OrderedDict()\n",
    "    for v, b in volta_bert_mapping.items():\n",
    "        if b is None:\n",
    "            data = {'transfarred': False, 'volta_weight':v, 'bert_weight':b, 'delta':None, 'volta_avg':None, 'bert_avg':None}\n",
    "        else:\n",
    "            x = volta_state_dict[v]\n",
    "            y = bert_state_dict[b]\n",
    "            # Note: when type_vocab_size is different from bert-bassed-uncased,\n",
    "            # the first two embeddings were transferred from BERT.  \n",
    "            if v == 'embeddings.token_type_embeddings.weight':\n",
    "                x = x[:2]\n",
    "            delta = (abs(x - y)).sum().item() / x.numel()\n",
    "            cossim = (x*y).sum() / ((x*x).sum()*(y*y).sum())**0.5\n",
    "            volta_avg = abs(x).sum().item() / x.numel()\n",
    "            bert_avg = abs(y).sum().item() / y.numel()\n",
    "            data = {'transfarred': True, 'volta_weight':v, 'bert_weight':b, 'delta':delta, 'cossim':cossim, 'volta_avg':volta_avg, 'bert_avg':bert_avg}\n",
    "        results[v] = data\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68865206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_weight_table(table):\n",
    "    \n",
    "    print('total_weights (tensors)', len(table))\n",
    "    \n",
    "    transferred_weights = list(filter(lambda r:r['transfarred'], table.values()))\n",
    "    print('total_transferred_weights (tensors)', len(transferred_weights))\n",
    "    \n",
    "    weight_types = ('layer_norm_bias', 'layer_norm_weight', 'normal_bias','normal_weight', 'all_bias', 'all_weight')\n",
    "    \n",
    "    cossim = {k:[] for k  in weight_types}\n",
    "    delta = {k:[] for k  in weight_types}\n",
    "    volta_avg = {k:[] for k  in weight_types}\n",
    "    bert_avg = {k:[] for k  in weight_types}\n",
    "    \n",
    "    for w in transferred_weights:\n",
    "        key = w['volta_weight']\n",
    "        if key.endswith('.LayerNorm.weight'):\n",
    "            t = 'layer_norm_weight'\n",
    "            tl = 'all_weight'\n",
    "        elif key.endswith('.LayerNorm.bias'):\n",
    "            t = 'layer_norm_bias'\n",
    "            tl = 'all_bias'\n",
    "        elif key.endswith('.weight'):\n",
    "            t = 'normal_weight'\n",
    "            tl = 'all_weight'\n",
    "        elif key.endswith('.bias'):\n",
    "            t = 'normal_bias'\n",
    "            tl = 'all_bias'\n",
    "        else:\n",
    "            print('unknown type:', key)    \n",
    "        \n",
    "        for _ in (t, tl):\n",
    "            delta[_].append(w['delta'])\n",
    "            cossim[_].append(w['cossim'])\n",
    "            volta_avg[_].append(w['volta_avg'])\n",
    "            bert_avg[_].append(w['bert_avg'])\n",
    "        \n",
    "    mean = lambda l: sum(l) / (len(l) or 1)\n",
    "    \n",
    "    print('type', 'n', 'volta_avg', 'bert_avg', 'delta_avg', 'cossim_avg', sep='\\t')\n",
    "    for t in  weight_types:\n",
    "        print(t, len(delta[t]), '%.5f'%mean(volta_avg[t]), '%.5f'%mean(bert_avg[t]), '%.5f'%mean(delta[t]), '%.5f'%mean(cossim[t]), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44efe498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../vl_models/pretrained/ctrl_visual_bert:\n",
      "total_weights (tensors) 399\n",
      "total_transferred_weights (tensors) 197\n",
      "type\tn\tvolta_avg\tbert_avg\tdelta_avg\tcossim_avg\n",
      "layer_norm_bias\t25\t0.08202\t0.07927\t0.00668\t0.99726\n",
      "layer_norm_weight\t25\t0.83292\t0.83128\t0.01116\t0.99992\n",
      "normal_bias\t72\t0.05829\t0.05761\t0.00447\t0.99632\n",
      "normal_weight\t75\t0.03053\t0.02978\t0.01194\t0.92177\n",
      "all_bias\t97\t0.06441\t0.06319\t0.00504\t0.99657\n",
      "all_weight\t100\t0.23113\t0.23015\t0.01174\t0.94131\n",
      "\n",
      "../../vl_models/pretrained/ctrl_uniter:\n",
      "total_weights (tensors) 405\n",
      "total_transferred_weights (tensors) 197\n",
      "type\tn\tvolta_avg\tbert_avg\tdelta_avg\tcossim_avg\n",
      "layer_norm_bias\t25\t0.08183\t0.07927\t0.00661\t0.99709\n",
      "layer_norm_weight\t25\t0.83259\t0.83128\t0.01065\t0.99991\n",
      "normal_bias\t72\t0.05831\t0.05761\t0.00450\t0.99655\n",
      "normal_weight\t75\t0.03057\t0.02978\t0.01212\t0.91972\n",
      "all_bias\t97\t0.06437\t0.06319\t0.00505\t0.99669\n",
      "all_weight\t100\t0.23108\t0.23015\t0.01175\t0.93977\n",
      "\n",
      "../../vl_models/pretrained/ctrl_vl_bert:\n",
      "total_weights (tensors) 404\n",
      "total_transferred_weights (tensors) 197\n",
      "type\tn\tvolta_avg\tbert_avg\tdelta_avg\tcossim_avg\n",
      "layer_norm_bias\t25\t0.08184\t0.07927\t0.00675\t0.99683\n",
      "layer_norm_weight\t25\t0.83239\t0.83128\t0.01093\t0.99991\n",
      "normal_bias\t72\t0.05833\t0.05761\t0.00453\t0.99635\n",
      "normal_weight\t75\t0.03049\t0.02978\t0.01210\t0.91927\n",
      "all_bias\t97\t0.06439\t0.06319\t0.00510\t0.99647\n",
      "all_weight\t100\t0.23097\t0.23015\t0.01180\t0.93943\n",
      "\n",
      "../../vl_models/pretrained/ctrl_lxmert:\n",
      "total_weights (tensors) 503\n",
      "total_transferred_weights (tensors) 197\n",
      "type\tn\tvolta_avg\tbert_avg\tdelta_avg\tcossim_avg\n",
      "layer_norm_bias\t25\t0.08284\t0.07927\t0.00829\t0.99352\n",
      "layer_norm_weight\t25\t0.83499\t0.83128\t0.01227\t0.99982\n",
      "normal_bias\t72\t0.05835\t0.05761\t0.00523\t0.99262\n",
      "normal_weight\t75\t0.03042\t0.02978\t0.01199\t0.92079\n",
      "all_bias\t97\t0.06466\t0.06319\t0.00602\t0.99286\n",
      "all_weight\t100\t0.23156\t0.23015\t0.01206\t0.94055\n",
      "\n",
      "../../vl_models/pretrained/ctrl_vilbert:\n",
      "total_weights (tensors) 497\n",
      "total_transferred_weights (tensors) 197\n",
      "type\tn\tvolta_avg\tbert_avg\tdelta_avg\tcossim_avg\n",
      "layer_norm_bias\t25\t0.08222\t0.07927\t0.01030\t0.98946\n",
      "layer_norm_weight\t25\t0.83814\t0.83128\t0.01533\t0.99988\n",
      "normal_bias\t72\t0.05824\t0.05761\t0.00484\t0.99343\n",
      "normal_weight\t75\t0.03005\t0.02978\t0.01186\t0.92184\n",
      "all_bias\t97\t0.06442\t0.06319\t0.00625\t0.99240\n",
      "all_weight\t100\t0.23207\t0.23015\t0.01273\t0.94135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run analysis on each model.\n",
    "bert_model = transformers_volta.AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model_paths = [\n",
    "    '../../vl_models/pretrained/ctrl_visual_bert',\n",
    "    '../../vl_models/pretrained/ctrl_uniter',\n",
    "    '../../vl_models/pretrained/ctrl_vl_bert',\n",
    "    '../../vl_models/pretrained/ctrl_lxmert',\n",
    "    '../../vl_models/pretrained/ctrl_vilbert',\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    volta_model = transformers_volta.AutoModel.from_pretrained(model_path)\n",
    "    table = get_weight_table(bert_model, volta_model)\n",
    "    print(model_path+':')\n",
    "    summarize_weight_table(table)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b362f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
