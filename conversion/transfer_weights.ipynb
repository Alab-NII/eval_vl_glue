{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/butd/venv/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "03/30/2021 18:27:46 - INFO - pytorch_transformers.modeling_bert -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "03/30/2021 18:27:46 - INFO - pytorch_transformers.modeling_xlnet -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import torch\n",
    "import transformers\n",
    "from  transformers.models.volta.convert import transfer_from\n",
    "from volta.datasets._image_features_reader import ImageFeaturesH5Reader\n",
    "\n",
    "\n",
    "def compile_model(config_path, weight_path, output_path, dummy_imgfeats):\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print('output path already exists', output_path)\n",
    "        return\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "    config = None\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        del config['clf_hidden_size']\n",
    "        config = transformers.models.volta.VoltaConfig.from_dict(config)\n",
    "    \n",
    "    tokenizer = transformers.models.volta.VoltaTokenizer.from_pretrained(\n",
    "        'bert-base-uncased', \n",
    "        model_max_length=config.max_position_embeddings,\n",
    "    )\n",
    "    \n",
    "    model = transformers.models.volta.VoltaModel(config)\n",
    "    model = transfer_from(torch.load(weight_path), model)\n",
    "    set_dummy_imgfeats(dummy_imgfeats, config, model)\n",
    "    \n",
    "    config.save_pretrained(output_path)\n",
    "    tokenizer.save_pretrained(output_path)\n",
    "    model.save_pretrained(output_path)\n",
    "    \n",
    "\n",
    "def make_reinit_model(base_model_path, output_path):\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print('output path already exists', output_path)\n",
    "        return\n",
    "    os.makedirs(output_path)\n",
    "    \n",
    "    config = transformers.models.volta.VoltaConfig.from_pretrained(base_model_path)\n",
    "    model = transformers.models.volta.VoltaModel(config)\n",
    "    model = transfer_from('bert-base-uncased', model)\n",
    "    set_dummy_imgfeats(dummy_imgfeats, config, model)\n",
    "    \n",
    "    config.save_pretrained(output_path)\n",
    "    transformers.models.volta.VoltaTokenizer.from_pretrained(base_model_path).save_pretrained(output_path)\n",
    "    model.save_pretrained(output_path)\n",
    "\n",
    "    \n",
    "def set_dummy_imgfeats(dummy_imgfeats, config, model):\n",
    "    \n",
    "    feat_reader = ImageFeaturesH5Reader(dummy_imgfeats['path'], config)\n",
    "    features, num_boxes, image_location, image_location_ori = feat_reader[dummy_imgfeats['key']]\n",
    "    \n",
    "    target = model.dummy_input_imgs\n",
    "    x = torch.tensor(features[None], dtype=target.dtype)\n",
    "    assert x.shape == target.data.shape\n",
    "    target.data = x\n",
    "    \n",
    "    target = model.dummy_image_loc\n",
    "    x = torch.tensor(image_location[None], dtype=target.dtype)\n",
    "    assert x.shape == target.data.shape\n",
    "    target.data = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_imgfeats = {\n",
    "    'path': 'hf_volta_models/dummy_imgfeats.lmdb',\n",
    "    'key': 'black_224',\n",
    "}\n",
    "targets = [\n",
    "    {'config_path':'volta/config/ctrl_vilbert_base.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_vilbert', \n",
    "         'output_path':'hf_volta_models/ctrl_vilbert_base'},\n",
    "    \n",
    "    {'config_path':'volta/config/ctrl_lxmert.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_lexmert', \n",
    "         'output_path':'hf_volta_models/ctrl_lxmert_base'},\n",
    "    \n",
    "    {'config_path':'volta/config/ctrl_uniter_base.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_uniter', \n",
    "         'output_path':'hf_volta_models/ctrl_uniter_base'},\n",
    "    \n",
    "    {'config_path':'volta/config/ctrl_visualbert_base.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_visual_bert', \n",
    "         'output_path':'hf_volta_models/ctrl_visual_bert_base'},\n",
    "    \n",
    "    {'config_path':'volta/config/ctrl_vl-bert_base.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_vl_bert', \n",
    "         'output_path':'hf_volta_models/ctrl_vl_bert_base'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_vilbert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_vilbert', 'output_path': 'hf_volta_models/ctrl_vilbert_base'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_vilbert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_vilbert', 'output_path': 'hf_volta_models/ctrl_vilbert_base'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.34.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.34.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.34.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.34.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.34.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.34.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.34.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.34.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.34.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.34.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.35.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.35.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.35.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.35.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.35.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.35.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.30.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.30.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.30.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.30.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.30.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.30.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.30.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.30.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.30.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.30.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.31.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.31.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.31.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.31.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.31.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.31.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.26.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.26.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.26.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.26.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.26.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.26.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.26.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.26.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.26.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.26.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.27.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.27.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.27.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.27.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.27.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.27.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.18.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.18.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.18.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.18.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.18.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.18.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.18.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.18.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.18.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.18.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.19.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.19.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.19.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.19.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.19.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.19.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'v_embeddings.image_embeddings.weight', 'v_embeddings.image_embeddings.bias', 'v_embeddings.image_location_embeddings.weight', 'v_embeddings.image_location_embeddings.bias', 'v_embeddings.LayerNorm.weight', 'v_embeddings.LayerNorm.bias', 'encoder.layer.12.attention_self.query.weight', 'encoder.layer.12.attention_self.query.bias', 'encoder.layer.12.attention_self.key.weight', 'encoder.layer.12.attention_self.key.bias', 'encoder.layer.12.attention_self.value.weight', 'encoder.layer.12.attention_self.value.bias', 'encoder.layer.12.attention_self.v_query.weight', 'encoder.layer.12.attention_self.v_query.bias', 'encoder.layer.12.attention_self.v_key.weight', 'encoder.layer.12.attention_self.v_key.bias', 'encoder.layer.12.attention_self.v_value.weight', 'encoder.layer.12.attention_self.v_value.bias', 'encoder.layer.12.attention_output.dense.weight', 'encoder.layer.12.attention_output.dense.bias', 'encoder.layer.12.attention_output.LayerNorm.weight', 'encoder.layer.12.attention_output.LayerNorm.bias', 'encoder.layer.12.attention_output.v_dense.weight', 'encoder.layer.12.attention_output.v_dense.bias', 'encoder.layer.12.attention_output.v_LayerNorm.weight', 'encoder.layer.12.attention_output.v_LayerNorm.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.v_dense.weight', 'encoder.layer.13.intermediate.v_dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.13.output.v_dense.weight', 'encoder.layer.13.output.v_dense.bias', 'encoder.layer.13.output.v_LayerNorm.weight', 'encoder.layer.13.output.v_LayerNorm.bias', 'encoder.layer.14.attention_self.v_query.weight', 'encoder.layer.14.attention_self.v_query.bias', 'encoder.layer.14.attention_self.v_key.weight', 'encoder.layer.14.attention_self.v_key.bias', 'encoder.layer.14.attention_self.v_value.weight', 'encoder.layer.14.attention_self.v_value.bias', 'encoder.layer.14.attention_output.v_dense.weight', 'encoder.layer.14.attention_output.v_dense.bias', 'encoder.layer.14.attention_output.v_LayerNorm.weight', 'encoder.layer.14.attention_output.v_LayerNorm.bias', 'encoder.layer.15.intermediate.v_dense.weight', 'encoder.layer.15.intermediate.v_dense.bias', 'encoder.layer.15.output.v_dense.weight', 'encoder.layer.15.output.v_dense.bias', 'encoder.layer.15.output.v_LayerNorm.weight', 'encoder.layer.15.output.v_LayerNorm.bias', 'encoder.layer.16.attention_self.query.weight', 'encoder.layer.16.attention_self.query.bias', 'encoder.layer.16.attention_self.key.weight', 'encoder.layer.16.attention_self.key.bias', 'encoder.layer.16.attention_self.value.weight', 'encoder.layer.16.attention_self.value.bias', 'encoder.layer.16.attention_self.v_query.weight', 'encoder.layer.16.attention_self.v_query.bias', 'encoder.layer.16.attention_self.v_key.weight', 'encoder.layer.16.attention_self.v_key.bias', 'encoder.layer.16.attention_self.v_value.weight', 'encoder.layer.16.attention_self.v_value.bias', 'encoder.layer.16.attention_output.dense.weight', 'encoder.layer.16.attention_output.dense.bias', 'encoder.layer.16.attention_output.LayerNorm.weight', 'encoder.layer.16.attention_output.LayerNorm.bias', 'encoder.layer.16.attention_output.v_dense.weight', 'encoder.layer.16.attention_output.v_dense.bias', 'encoder.layer.16.attention_output.v_LayerNorm.weight', 'encoder.layer.16.attention_output.v_LayerNorm.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.v_dense.weight', 'encoder.layer.17.intermediate.v_dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.17.output.v_dense.weight', 'encoder.layer.17.output.v_dense.bias', 'encoder.layer.17.output.v_LayerNorm.weight', 'encoder.layer.17.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.intermediate.v_dense.weight', 'encoder.layer.19.intermediate.v_dense.bias', 'encoder.layer.19.output.v_dense.weight', 'encoder.layer.19.output.v_dense.bias', 'encoder.layer.19.output.v_LayerNorm.weight', 'encoder.layer.19.output.v_LayerNorm.bias', 'encoder.layer.20.attention_self.query.weight', 'encoder.layer.20.attention_self.query.bias', 'encoder.layer.20.attention_self.key.weight', 'encoder.layer.20.attention_self.key.bias', 'encoder.layer.20.attention_self.value.weight', 'encoder.layer.20.attention_self.value.bias', 'encoder.layer.20.attention_self.v_query.weight', 'encoder.layer.20.attention_self.v_query.bias', 'encoder.layer.20.attention_self.v_key.weight', 'encoder.layer.20.attention_self.v_key.bias', 'encoder.layer.20.attention_self.v_value.weight', 'encoder.layer.20.attention_self.v_value.bias', 'encoder.layer.20.attention_output.dense.weight', 'encoder.layer.20.attention_output.dense.bias', 'encoder.layer.20.attention_output.LayerNorm.weight', 'encoder.layer.20.attention_output.LayerNorm.bias', 'encoder.layer.20.attention_output.v_dense.weight', 'encoder.layer.20.attention_output.v_dense.bias', 'encoder.layer.20.attention_output.v_LayerNorm.weight', 'encoder.layer.20.attention_output.v_LayerNorm.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.v_dense.weight', 'encoder.layer.21.intermediate.v_dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.21.output.v_dense.weight', 'encoder.layer.21.output.v_dense.bias', 'encoder.layer.21.output.v_LayerNorm.weight', 'encoder.layer.21.output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 'encoder.layer.24.attention_self.query.weight', 'encoder.layer.24.attention_self.query.bias', 'encoder.layer.24.attention_self.key.weight', 'encoder.layer.24.attention_self.key.bias', 'encoder.layer.24.attention_self.value.weight', 'encoder.layer.24.attention_self.value.bias', 'encoder.layer.24.attention_self.v_query.weight', 'encoder.layer.24.attention_self.v_query.bias', 'encoder.layer.24.attention_self.v_key.weight', 'encoder.layer.24.attention_self.v_key.bias', 'encoder.layer.24.attention_self.v_value.weight', 'encoder.layer.24.attention_self.v_value.bias', 'encoder.layer.24.attention_output.dense.weight', 'encoder.layer.24.attention_output.dense.bias', 'encoder.layer.24.attention_output.LayerNorm.weight', 'encoder.layer.24.attention_output.LayerNorm.bias', 'encoder.layer.24.attention_output.v_dense.weight', 'encoder.layer.24.attention_output.v_dense.bias', 'encoder.layer.24.attention_output.v_LayerNorm.weight', 'encoder.layer.24.attention_output.v_LayerNorm.bias', 'encoder.layer.25.intermediate.dense.weight', 'encoder.layer.25.intermediate.dense.bias', 'encoder.layer.25.intermediate.v_dense.weight', 'encoder.layer.25.intermediate.v_dense.bias', 'encoder.layer.25.output.dense.weight', 'encoder.layer.25.output.dense.bias', 'encoder.layer.25.output.LayerNorm.weight', 'encoder.layer.25.output.LayerNorm.bias', 'encoder.layer.25.output.v_dense.weight', 'encoder.layer.25.output.v_dense.bias', 'encoder.layer.25.output.v_LayerNorm.weight', 'encoder.layer.25.output.v_LayerNorm.bias', 'encoder.layer.26.attention_self.v_query.weight', 'encoder.layer.26.attention_self.v_query.bias', 'encoder.layer.26.attention_self.v_key.weight', 'encoder.layer.26.attention_self.v_key.bias', 'encoder.layer.26.attention_self.v_value.weight', 'encoder.layer.26.attention_self.v_value.bias', 'encoder.layer.26.attention_output.v_dense.weight', 'encoder.layer.26.attention_output.v_dense.bias', 'encoder.layer.26.attention_output.v_LayerNorm.weight', 'encoder.layer.26.attention_output.v_LayerNorm.bias', 'encoder.layer.27.intermediate.v_dense.weight', 'encoder.layer.27.intermediate.v_dense.bias', 'encoder.layer.27.output.v_dense.weight', 'encoder.layer.27.output.v_dense.bias', 'encoder.layer.27.output.v_LayerNorm.weight', 'encoder.layer.27.output.v_LayerNorm.bias', 'encoder.layer.28.attention_self.query.weight', 'encoder.layer.28.attention_self.query.bias', 'encoder.layer.28.attention_self.key.weight', 'encoder.layer.28.attention_self.key.bias', 'encoder.layer.28.attention_self.value.weight', 'encoder.layer.28.attention_self.value.bias', 'encoder.layer.28.attention_self.v_query.weight', 'encoder.layer.28.attention_self.v_query.bias', 'encoder.layer.28.attention_self.v_key.weight', 'encoder.layer.28.attention_self.v_key.bias', 'encoder.layer.28.attention_self.v_value.weight', 'encoder.layer.28.attention_self.v_value.bias', 'encoder.layer.28.attention_output.dense.weight', 'encoder.layer.28.attention_output.dense.bias', 'encoder.layer.28.attention_output.LayerNorm.weight', 'encoder.layer.28.attention_output.LayerNorm.bias', 'encoder.layer.28.attention_output.v_dense.weight', 'encoder.layer.28.attention_output.v_dense.bias', 'encoder.layer.28.attention_output.v_LayerNorm.weight', 'encoder.layer.28.attention_output.v_LayerNorm.bias', 'encoder.layer.29.intermediate.dense.weight', 'encoder.layer.29.intermediate.dense.bias', 'encoder.layer.29.intermediate.v_dense.weight', 'encoder.layer.29.intermediate.v_dense.bias', 'encoder.layer.29.output.dense.weight', 'encoder.layer.29.output.dense.bias', 'encoder.layer.29.output.LayerNorm.weight', 'encoder.layer.29.output.LayerNorm.bias', 'encoder.layer.29.output.v_dense.weight', 'encoder.layer.29.output.v_dense.bias', 'encoder.layer.29.output.v_LayerNorm.weight', 'encoder.layer.29.output.v_LayerNorm.bias', 'encoder.layer.30.attention_self.v_query.weight', 'encoder.layer.30.attention_self.v_query.bias', 'encoder.layer.30.attention_self.v_key.weight', 'encoder.layer.30.attention_self.v_key.bias', 'encoder.layer.30.attention_self.v_value.weight', 'encoder.layer.30.attention_self.v_value.bias', 'encoder.layer.30.attention_output.v_dense.weight', 'encoder.layer.30.attention_output.v_dense.bias', 'encoder.layer.30.attention_output.v_LayerNorm.weight', 'encoder.layer.30.attention_output.v_LayerNorm.bias', 'encoder.layer.31.intermediate.v_dense.weight', 'encoder.layer.31.intermediate.v_dense.bias', 'encoder.layer.31.output.v_dense.weight', 'encoder.layer.31.output.v_dense.bias', 'encoder.layer.31.output.v_LayerNorm.weight', 'encoder.layer.31.output.v_LayerNorm.bias', 'encoder.layer.32.attention_self.query.weight', 'encoder.layer.32.attention_self.query.bias', 'encoder.layer.32.attention_self.key.weight', 'encoder.layer.32.attention_self.key.bias', 'encoder.layer.32.attention_self.value.weight', 'encoder.layer.32.attention_self.value.bias', 'encoder.layer.32.attention_self.v_query.weight', 'encoder.layer.32.attention_self.v_query.bias', 'encoder.layer.32.attention_self.v_key.weight', 'encoder.layer.32.attention_self.v_key.bias', 'encoder.layer.32.attention_self.v_value.weight', 'encoder.layer.32.attention_self.v_value.bias', 'encoder.layer.32.attention_output.dense.weight', 'encoder.layer.32.attention_output.dense.bias', 'encoder.layer.32.attention_output.LayerNorm.weight', 'encoder.layer.32.attention_output.LayerNorm.bias', 'encoder.layer.32.attention_output.v_dense.weight', 'encoder.layer.32.attention_output.v_dense.bias', 'encoder.layer.32.attention_output.v_LayerNorm.weight', 'encoder.layer.32.attention_output.v_LayerNorm.bias', 'encoder.layer.33.intermediate.dense.weight', 'encoder.layer.33.intermediate.dense.bias', 'encoder.layer.33.intermediate.v_dense.weight', 'encoder.layer.33.intermediate.v_dense.bias', 'encoder.layer.33.output.dense.weight', 'encoder.layer.33.output.dense.bias', 'encoder.layer.33.output.LayerNorm.weight', 'encoder.layer.33.output.LayerNorm.bias', 'encoder.layer.33.output.v_dense.weight', 'encoder.layer.33.output.v_dense.bias', 'encoder.layer.33.output.v_LayerNorm.weight', 'encoder.layer.33.output.v_LayerNorm.bias', 'encoder.layer.34.attention_self.v_query.weight', 'encoder.layer.34.attention_self.v_query.bias', 'encoder.layer.34.attention_self.v_key.weight', 'encoder.layer.34.attention_self.v_key.bias', 'encoder.layer.34.attention_self.v_value.weight', 'encoder.layer.34.attention_self.v_value.bias', 'encoder.layer.34.attention_output.v_dense.weight', 'encoder.layer.34.attention_output.v_dense.bias', 'encoder.layer.34.attention_output.v_LayerNorm.weight', 'encoder.layer.34.attention_output.v_LayerNorm.bias', 'encoder.layer.35.intermediate.v_dense.weight', 'encoder.layer.35.intermediate.v_dense.bias', 'encoder.layer.35.output.v_dense.weight', 'encoder.layer.35.output.v_dense.bias', 'encoder.layer.35.output.v_LayerNorm.weight', 'encoder.layer.35.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_lxmert.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_lexmert', 'output_path': 'hf_volta_models/ctrl_lxmert_base'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_lxmert.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_lexmert', 'output_path': 'hf_volta_models/ctrl_lxmert_base'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.25.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.25.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.25.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.25.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.25.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.25.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.25.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.25.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.25.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.25.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.26.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.26.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.26.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.26.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.26.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.26.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.19.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.19.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.19.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.19.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.19.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.19.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.19.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.19.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.19.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.19.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.20.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.20.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.20.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.20.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.20.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.20.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.16.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.16.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.16.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.16.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.16.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.16.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.16.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.16.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.16.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.16.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.17.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.17.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.17.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.17.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.17.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.17.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.12.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.12.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.12.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.12.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.12.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.12.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.12.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.12.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.12.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.12.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.13.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.13.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.13.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.13.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.13.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.13.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'v_embeddings.image_embeddings.weight', 'v_embeddings.image_embeddings.bias', 'v_embeddings.image_location_embeddings.weight', 'v_embeddings.image_location_embeddings.bias', 'v_embeddings.ImgLayerNorm.weight', 'v_embeddings.ImgLayerNorm.bias', 'v_embeddings.LocLayerNorm.weight', 'v_embeddings.LocLayerNorm.bias', 'encoder.layer.0.attention_self.v_query.weight', 'encoder.layer.0.attention_self.v_query.bias', 'encoder.layer.0.attention_self.v_key.weight', 'encoder.layer.0.attention_self.v_key.bias', 'encoder.layer.0.attention_self.v_value.weight', 'encoder.layer.0.attention_self.v_value.bias', 'encoder.layer.0.attention_output.v_dense.weight', 'encoder.layer.0.attention_output.v_dense.bias', 'encoder.layer.0.attention_output.v_LayerNorm.weight', 'encoder.layer.0.attention_output.v_LayerNorm.bias', 'encoder.layer.1.intermediate.v_dense.weight', 'encoder.layer.1.intermediate.v_dense.bias', 'encoder.layer.1.output.v_dense.weight', 'encoder.layer.1.output.v_dense.bias', 'encoder.layer.1.output.v_LayerNorm.weight', 'encoder.layer.1.output.v_LayerNorm.bias', 'encoder.layer.2.attention_self.v_query.weight', 'encoder.layer.2.attention_self.v_query.bias', 'encoder.layer.2.attention_self.v_key.weight', 'encoder.layer.2.attention_self.v_key.bias', 'encoder.layer.2.attention_self.v_value.weight', 'encoder.layer.2.attention_self.v_value.bias', 'encoder.layer.2.attention_output.v_dense.weight', 'encoder.layer.2.attention_output.v_dense.bias', 'encoder.layer.2.attention_output.v_LayerNorm.weight', 'encoder.layer.2.attention_output.v_LayerNorm.bias', 'encoder.layer.3.intermediate.v_dense.weight', 'encoder.layer.3.intermediate.v_dense.bias', 'encoder.layer.3.output.v_dense.weight', 'encoder.layer.3.output.v_dense.bias', 'encoder.layer.3.output.v_LayerNorm.weight', 'encoder.layer.3.output.v_LayerNorm.bias', 'encoder.layer.4.attention_self.v_query.weight', 'encoder.layer.4.attention_self.v_query.bias', 'encoder.layer.4.attention_self.v_key.weight', 'encoder.layer.4.attention_self.v_key.bias', 'encoder.layer.4.attention_self.v_value.weight', 'encoder.layer.4.attention_self.v_value.bias', 'encoder.layer.4.attention_output.v_dense.weight', 'encoder.layer.4.attention_output.v_dense.bias', 'encoder.layer.4.attention_output.v_LayerNorm.weight', 'encoder.layer.4.attention_output.v_LayerNorm.bias', 'encoder.layer.5.intermediate.v_dense.weight', 'encoder.layer.5.intermediate.v_dense.bias', 'encoder.layer.5.output.v_dense.weight', 'encoder.layer.5.output.v_dense.bias', 'encoder.layer.5.output.v_LayerNorm.weight', 'encoder.layer.5.output.v_LayerNorm.bias', 'encoder.layer.6.attention_self.v_query.weight', 'encoder.layer.6.attention_self.v_query.bias', 'encoder.layer.6.attention_self.v_key.weight', 'encoder.layer.6.attention_self.v_key.bias', 'encoder.layer.6.attention_self.v_value.weight', 'encoder.layer.6.attention_self.v_value.bias', 'encoder.layer.6.attention_output.v_dense.weight', 'encoder.layer.6.attention_output.v_dense.bias', 'encoder.layer.6.attention_output.v_LayerNorm.weight', 'encoder.layer.6.attention_output.v_LayerNorm.bias', 'encoder.layer.7.intermediate.v_dense.weight', 'encoder.layer.7.intermediate.v_dense.bias', 'encoder.layer.7.output.v_dense.weight', 'encoder.layer.7.output.v_dense.bias', 'encoder.layer.7.output.v_LayerNorm.weight', 'encoder.layer.7.output.v_LayerNorm.bias', 'encoder.layer.8.attention_self.v_query.weight', 'encoder.layer.8.attention_self.v_query.bias', 'encoder.layer.8.attention_self.v_key.weight', 'encoder.layer.8.attention_self.v_key.bias', 'encoder.layer.8.attention_self.v_value.weight', 'encoder.layer.8.attention_self.v_value.bias', 'encoder.layer.8.attention_output.v_dense.weight', 'encoder.layer.8.attention_output.v_dense.bias', 'encoder.layer.8.attention_output.v_LayerNorm.weight', 'encoder.layer.8.attention_output.v_LayerNorm.bias', 'encoder.layer.9.intermediate.v_dense.weight', 'encoder.layer.9.intermediate.v_dense.bias', 'encoder.layer.9.output.v_dense.weight', 'encoder.layer.9.output.v_dense.bias', 'encoder.layer.9.output.v_LayerNorm.weight', 'encoder.layer.9.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.query.weight', 'encoder.layer.18.attention_self.query.bias', 'encoder.layer.18.attention_self.key.weight', 'encoder.layer.18.attention_self.key.bias', 'encoder.layer.18.attention_self.value.weight', 'encoder.layer.18.attention_self.value.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.dense.weight', 'encoder.layer.18.attention_output.dense.bias', 'encoder.layer.18.attention_output.LayerNorm.weight', 'encoder.layer.18.attention_output.LayerNorm.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.attention_self.v_query.weight', 'encoder.layer.19.attention_self.v_query.bias', 'encoder.layer.19.attention_self.v_key.weight', 'encoder.layer.19.attention_self.v_key.bias', 'encoder.layer.19.attention_self.v_value.weight', 'encoder.layer.19.attention_self.v_value.bias', 'encoder.layer.19.attention_output.v_dense.weight', 'encoder.layer.19.attention_output.v_dense.bias', 'encoder.layer.19.attention_output.v_LayerNorm.weight', 'encoder.layer.19.attention_output.v_LayerNorm.bias', 'encoder.layer.20.intermediate.v_dense.weight', 'encoder.layer.20.intermediate.v_dense.bias', 'encoder.layer.20.output.v_dense.weight', 'encoder.layer.20.output.v_dense.bias', 'encoder.layer.20.output.v_LayerNorm.weight', 'encoder.layer.20.output.v_LayerNorm.bias', 'encoder.layer.21.attention_self.query.weight', 'encoder.layer.21.attention_self.query.bias', 'encoder.layer.21.attention_self.key.weight', 'encoder.layer.21.attention_self.key.bias', 'encoder.layer.21.attention_self.value.weight', 'encoder.layer.21.attention_self.value.bias', 'encoder.layer.21.attention_self.v_query.weight', 'encoder.layer.21.attention_self.v_query.bias', 'encoder.layer.21.attention_self.v_key.weight', 'encoder.layer.21.attention_self.v_key.bias', 'encoder.layer.21.attention_self.v_value.weight', 'encoder.layer.21.attention_self.v_value.bias', 'encoder.layer.21.attention_output.dense.weight', 'encoder.layer.21.attention_output.dense.bias', 'encoder.layer.21.attention_output.LayerNorm.weight', 'encoder.layer.21.attention_output.LayerNorm.bias', 'encoder.layer.21.attention_output.v_dense.weight', 'encoder.layer.21.attention_output.v_dense.bias', 'encoder.layer.21.attention_output.v_LayerNorm.weight', 'encoder.layer.21.attention_output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 'encoder.layer.24.attention_self.query.weight', 'encoder.layer.24.attention_self.query.bias', 'encoder.layer.24.attention_self.key.weight', 'encoder.layer.24.attention_self.key.bias', 'encoder.layer.24.attention_self.value.weight', 'encoder.layer.24.attention_self.value.bias', 'encoder.layer.24.attention_self.v_query.weight', 'encoder.layer.24.attention_self.v_query.bias', 'encoder.layer.24.attention_self.v_key.weight', 'encoder.layer.24.attention_self.v_key.bias', 'encoder.layer.24.attention_self.v_value.weight', 'encoder.layer.24.attention_self.v_value.bias', 'encoder.layer.24.attention_output.dense.weight', 'encoder.layer.24.attention_output.dense.bias', 'encoder.layer.24.attention_output.LayerNorm.weight', 'encoder.layer.24.attention_output.LayerNorm.bias', 'encoder.layer.24.attention_output.v_dense.weight', 'encoder.layer.24.attention_output.v_dense.bias', 'encoder.layer.24.attention_output.v_LayerNorm.weight', 'encoder.layer.24.attention_output.v_LayerNorm.bias', 'encoder.layer.25.attention_self.v_query.weight', 'encoder.layer.25.attention_self.v_query.bias', 'encoder.layer.25.attention_self.v_key.weight', 'encoder.layer.25.attention_self.v_key.bias', 'encoder.layer.25.attention_self.v_value.weight', 'encoder.layer.25.attention_self.v_value.bias', 'encoder.layer.25.attention_output.v_dense.weight', 'encoder.layer.25.attention_output.v_dense.bias', 'encoder.layer.25.attention_output.v_LayerNorm.weight', 'encoder.layer.25.attention_output.v_LayerNorm.bias', 'encoder.layer.26.intermediate.v_dense.weight', 'encoder.layer.26.intermediate.v_dense.bias', 'encoder.layer.26.output.v_dense.weight', 'encoder.layer.26.output.v_dense.bias', 'encoder.layer.26.output.v_LayerNorm.weight', 'encoder.layer.26.output.v_LayerNorm.bias', 'encoder.layer.27.attention_self.query.weight', 'encoder.layer.27.attention_self.query.bias', 'encoder.layer.27.attention_self.key.weight', 'encoder.layer.27.attention_self.key.bias', 'encoder.layer.27.attention_self.value.weight', 'encoder.layer.27.attention_self.value.bias', 'encoder.layer.27.attention_self.v_query.weight', 'encoder.layer.27.attention_self.v_query.bias', 'encoder.layer.27.attention_self.v_key.weight', 'encoder.layer.27.attention_self.v_key.bias', 'encoder.layer.27.attention_self.v_value.weight', 'encoder.layer.27.attention_self.v_value.bias', 'encoder.layer.27.attention_output.dense.weight', 'encoder.layer.27.attention_output.dense.bias', 'encoder.layer.27.attention_output.LayerNorm.weight', 'encoder.layer.27.attention_output.LayerNorm.bias', 'encoder.layer.27.attention_output.v_dense.weight', 'encoder.layer.27.attention_output.v_dense.bias', 'encoder.layer.27.attention_output.v_LayerNorm.weight', 'encoder.layer.27.attention_output.v_LayerNorm.bias', 'encoder.layer.28.attention_self.query.weight', 'encoder.layer.28.attention_self.query.bias', 'encoder.layer.28.attention_self.key.weight', 'encoder.layer.28.attention_self.key.bias', 'encoder.layer.28.attention_self.value.weight', 'encoder.layer.28.attention_self.value.bias', 'encoder.layer.28.attention_self.v_query.weight', 'encoder.layer.28.attention_self.v_query.bias', 'encoder.layer.28.attention_self.v_key.weight', 'encoder.layer.28.attention_self.v_key.bias', 'encoder.layer.28.attention_self.v_value.weight', 'encoder.layer.28.attention_self.v_value.bias', 'encoder.layer.28.attention_output.dense.weight', 'encoder.layer.28.attention_output.dense.bias', 'encoder.layer.28.attention_output.LayerNorm.weight', 'encoder.layer.28.attention_output.LayerNorm.bias', 'encoder.layer.28.attention_output.v_dense.weight', 'encoder.layer.28.attention_output.v_dense.bias', 'encoder.layer.28.attention_output.v_LayerNorm.weight', 'encoder.layer.28.attention_output.v_LayerNorm.bias', 'encoder.layer.29.intermediate.dense.weight', 'encoder.layer.29.intermediate.dense.bias', 'encoder.layer.29.intermediate.v_dense.weight', 'encoder.layer.29.intermediate.v_dense.bias', 'encoder.layer.29.output.dense.weight', 'encoder.layer.29.output.dense.bias', 'encoder.layer.29.output.LayerNorm.weight', 'encoder.layer.29.output.LayerNorm.bias', 'encoder.layer.29.output.v_dense.weight', 'encoder.layer.29.output.v_dense.bias', 'encoder.layer.29.output.v_LayerNorm.weight', 'encoder.layer.29.output.v_LayerNorm.bias', 'encoder.layer.30.attention_self.query.weight', 'encoder.layer.30.attention_self.query.bias', 'encoder.layer.30.attention_self.key.weight', 'encoder.layer.30.attention_self.key.bias', 'encoder.layer.30.attention_self.value.weight', 'encoder.layer.30.attention_self.value.bias', 'encoder.layer.30.attention_self.v_query.weight', 'encoder.layer.30.attention_self.v_query.bias', 'encoder.layer.30.attention_self.v_key.weight', 'encoder.layer.30.attention_self.v_key.bias', 'encoder.layer.30.attention_self.v_value.weight', 'encoder.layer.30.attention_self.v_value.bias', 'encoder.layer.30.attention_output.dense.weight', 'encoder.layer.30.attention_output.dense.bias', 'encoder.layer.30.attention_output.LayerNorm.weight', 'encoder.layer.30.attention_output.LayerNorm.bias', 'encoder.layer.30.attention_output.v_dense.weight', 'encoder.layer.30.attention_output.v_dense.bias', 'encoder.layer.30.attention_output.v_LayerNorm.weight', 'encoder.layer.30.attention_output.v_LayerNorm.bias', 'encoder.layer.31.attention_self.query.weight', 'encoder.layer.31.attention_self.query.bias', 'encoder.layer.31.attention_self.key.weight', 'encoder.layer.31.attention_self.key.bias', 'encoder.layer.31.attention_self.value.weight', 'encoder.layer.31.attention_self.value.bias', 'encoder.layer.31.attention_self.v_query.weight', 'encoder.layer.31.attention_self.v_query.bias', 'encoder.layer.31.attention_self.v_key.weight', 'encoder.layer.31.attention_self.v_key.bias', 'encoder.layer.31.attention_self.v_value.weight', 'encoder.layer.31.attention_self.v_value.bias', 'encoder.layer.31.attention_output.dense.weight', 'encoder.layer.31.attention_output.dense.bias', 'encoder.layer.31.attention_output.LayerNorm.weight', 'encoder.layer.31.attention_output.LayerNorm.bias', 'encoder.layer.31.attention_output.v_dense.weight', 'encoder.layer.31.attention_output.v_dense.bias', 'encoder.layer.31.attention_output.v_LayerNorm.weight', 'encoder.layer.31.attention_output.v_LayerNorm.bias', 'encoder.layer.32.intermediate.dense.weight', 'encoder.layer.32.intermediate.dense.bias', 'encoder.layer.32.intermediate.v_dense.weight', 'encoder.layer.32.intermediate.v_dense.bias', 'encoder.layer.32.output.dense.weight', 'encoder.layer.32.output.dense.bias', 'encoder.layer.32.output.LayerNorm.weight', 'encoder.layer.32.output.LayerNorm.bias', 'encoder.layer.32.output.v_dense.weight', 'encoder.layer.32.output.v_dense.bias', 'encoder.layer.32.output.v_LayerNorm.weight', 'encoder.layer.32.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_uniter_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_uniter', 'output_path': 'hf_volta_models/ctrl_uniter_base'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_uniter_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_uniter', 'output_path': 'hf_volta_models/ctrl_uniter_base'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.20.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.20.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.20.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.20.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.20.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.20.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.20.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.20.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.20.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.20.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.21.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.21.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.21.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.21.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.21.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.21.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.18.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.18.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.18.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.18.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.18.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.18.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.18.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.18.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.18.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.18.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.19.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.19.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.19.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.19.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.19.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.19.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.16.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.16.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.16.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.16.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.16.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.16.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.16.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.16.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.16.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.16.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.17.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.17.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.17.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.17.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.17.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.17.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.12.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.12.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.12.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.12.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.12.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.12.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.12.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.12.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.12.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.12.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.13.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.13.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.13.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.13.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.13.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.13.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'embeddings.image_embeddings.weight', 'embeddings.image_embeddings.bias', 'embeddings.image_location_embeddings.weight', 'embeddings.image_location_embeddings.bias', 'embeddings.image_layer_norm.weight', 'embeddings.image_layer_norm.bias', 'embeddings.image_location_layer_norm.weight', 'embeddings.image_location_layer_norm.bias', 'embeddings.v_LayerNorm.weight', 'embeddings.v_LayerNorm.bias', 'encoder.layer.0.attention_self.v_query.weight', 'encoder.layer.0.attention_self.v_query.bias', 'encoder.layer.0.attention_self.v_key.weight', 'encoder.layer.0.attention_self.v_key.bias', 'encoder.layer.0.attention_self.v_value.weight', 'encoder.layer.0.attention_self.v_value.bias', 'encoder.layer.0.attention_output.v_dense.weight', 'encoder.layer.0.attention_output.v_dense.bias', 'encoder.layer.0.attention_output.v_LayerNorm.weight', 'encoder.layer.0.attention_output.v_LayerNorm.bias', 'encoder.layer.1.intermediate.v_dense.weight', 'encoder.layer.1.intermediate.v_dense.bias', 'encoder.layer.1.output.v_dense.weight', 'encoder.layer.1.output.v_dense.bias', 'encoder.layer.1.output.v_LayerNorm.weight', 'encoder.layer.1.output.v_LayerNorm.bias', 'encoder.layer.2.attention_self.v_query.weight', 'encoder.layer.2.attention_self.v_query.bias', 'encoder.layer.2.attention_self.v_key.weight', 'encoder.layer.2.attention_self.v_key.bias', 'encoder.layer.2.attention_self.v_value.weight', 'encoder.layer.2.attention_self.v_value.bias', 'encoder.layer.2.attention_output.v_dense.weight', 'encoder.layer.2.attention_output.v_dense.bias', 'encoder.layer.2.attention_output.v_LayerNorm.weight', 'encoder.layer.2.attention_output.v_LayerNorm.bias', 'encoder.layer.3.intermediate.v_dense.weight', 'encoder.layer.3.intermediate.v_dense.bias', 'encoder.layer.3.output.v_dense.weight', 'encoder.layer.3.output.v_dense.bias', 'encoder.layer.3.output.v_LayerNorm.weight', 'encoder.layer.3.output.v_LayerNorm.bias', 'encoder.layer.4.attention_self.v_query.weight', 'encoder.layer.4.attention_self.v_query.bias', 'encoder.layer.4.attention_self.v_key.weight', 'encoder.layer.4.attention_self.v_key.bias', 'encoder.layer.4.attention_self.v_value.weight', 'encoder.layer.4.attention_self.v_value.bias', 'encoder.layer.4.attention_output.v_dense.weight', 'encoder.layer.4.attention_output.v_dense.bias', 'encoder.layer.4.attention_output.v_LayerNorm.weight', 'encoder.layer.4.attention_output.v_LayerNorm.bias', 'encoder.layer.5.intermediate.v_dense.weight', 'encoder.layer.5.intermediate.v_dense.bias', 'encoder.layer.5.output.v_dense.weight', 'encoder.layer.5.output.v_dense.bias', 'encoder.layer.5.output.v_LayerNorm.weight', 'encoder.layer.5.output.v_LayerNorm.bias', 'encoder.layer.6.attention_self.v_query.weight', 'encoder.layer.6.attention_self.v_query.bias', 'encoder.layer.6.attention_self.v_key.weight', 'encoder.layer.6.attention_self.v_key.bias', 'encoder.layer.6.attention_self.v_value.weight', 'encoder.layer.6.attention_self.v_value.bias', 'encoder.layer.6.attention_output.v_dense.weight', 'encoder.layer.6.attention_output.v_dense.bias', 'encoder.layer.6.attention_output.v_LayerNorm.weight', 'encoder.layer.6.attention_output.v_LayerNorm.bias', 'encoder.layer.7.intermediate.v_dense.weight', 'encoder.layer.7.intermediate.v_dense.bias', 'encoder.layer.7.output.v_dense.weight', 'encoder.layer.7.output.v_dense.bias', 'encoder.layer.7.output.v_LayerNorm.weight', 'encoder.layer.7.output.v_LayerNorm.bias', 'encoder.layer.8.attention_self.v_query.weight', 'encoder.layer.8.attention_self.v_query.bias', 'encoder.layer.8.attention_self.v_key.weight', 'encoder.layer.8.attention_self.v_key.bias', 'encoder.layer.8.attention_self.v_value.weight', 'encoder.layer.8.attention_self.v_value.bias', 'encoder.layer.8.attention_output.v_dense.weight', 'encoder.layer.8.attention_output.v_dense.bias', 'encoder.layer.8.attention_output.v_LayerNorm.weight', 'encoder.layer.8.attention_output.v_LayerNorm.bias', 'encoder.layer.9.intermediate.v_dense.weight', 'encoder.layer.9.intermediate.v_dense.bias', 'encoder.layer.9.output.v_dense.weight', 'encoder.layer.9.output.v_dense.bias', 'encoder.layer.9.output.v_LayerNorm.weight', 'encoder.layer.9.output.v_LayerNorm.bias', 'encoder.layer.10.attention_self.v_query.weight', 'encoder.layer.10.attention_self.v_query.bias', 'encoder.layer.10.attention_self.v_key.weight', 'encoder.layer.10.attention_self.v_key.bias', 'encoder.layer.10.attention_self.v_value.weight', 'encoder.layer.10.attention_self.v_value.bias', 'encoder.layer.10.attention_output.v_dense.weight', 'encoder.layer.10.attention_output.v_dense.bias', 'encoder.layer.10.attention_output.v_LayerNorm.weight', 'encoder.layer.10.attention_output.v_LayerNorm.bias', 'encoder.layer.11.intermediate.v_dense.weight', 'encoder.layer.11.intermediate.v_dense.bias', 'encoder.layer.11.output.v_dense.weight', 'encoder.layer.11.output.v_dense.bias', 'encoder.layer.11.output.v_LayerNorm.weight', 'encoder.layer.11.output.v_LayerNorm.bias', 'encoder.layer.12.attention_self.v_query.weight', 'encoder.layer.12.attention_self.v_query.bias', 'encoder.layer.12.attention_self.v_key.weight', 'encoder.layer.12.attention_self.v_key.bias', 'encoder.layer.12.attention_self.v_value.weight', 'encoder.layer.12.attention_self.v_value.bias', 'encoder.layer.12.attention_output.v_dense.weight', 'encoder.layer.12.attention_output.v_dense.bias', 'encoder.layer.12.attention_output.v_LayerNorm.weight', 'encoder.layer.12.attention_output.v_LayerNorm.bias', 'encoder.layer.13.intermediate.v_dense.weight', 'encoder.layer.13.intermediate.v_dense.bias', 'encoder.layer.13.output.v_dense.weight', 'encoder.layer.13.output.v_dense.bias', 'encoder.layer.13.output.v_LayerNorm.weight', 'encoder.layer.13.output.v_LayerNorm.bias', 'encoder.layer.14.attention_self.v_query.weight', 'encoder.layer.14.attention_self.v_query.bias', 'encoder.layer.14.attention_self.v_key.weight', 'encoder.layer.14.attention_self.v_key.bias', 'encoder.layer.14.attention_self.v_value.weight', 'encoder.layer.14.attention_self.v_value.bias', 'encoder.layer.14.attention_output.v_dense.weight', 'encoder.layer.14.attention_output.v_dense.bias', 'encoder.layer.14.attention_output.v_LayerNorm.weight', 'encoder.layer.14.attention_output.v_LayerNorm.bias', 'encoder.layer.15.intermediate.v_dense.weight', 'encoder.layer.15.intermediate.v_dense.bias', 'encoder.layer.15.output.v_dense.weight', 'encoder.layer.15.output.v_dense.bias', 'encoder.layer.15.output.v_LayerNorm.weight', 'encoder.layer.15.output.v_LayerNorm.bias', 'encoder.layer.16.attention_self.v_query.weight', 'encoder.layer.16.attention_self.v_query.bias', 'encoder.layer.16.attention_self.v_key.weight', 'encoder.layer.16.attention_self.v_key.bias', 'encoder.layer.16.attention_self.v_value.weight', 'encoder.layer.16.attention_self.v_value.bias', 'encoder.layer.16.attention_output.v_dense.weight', 'encoder.layer.16.attention_output.v_dense.bias', 'encoder.layer.16.attention_output.v_LayerNorm.weight', 'encoder.layer.16.attention_output.v_LayerNorm.bias', 'encoder.layer.17.intermediate.v_dense.weight', 'encoder.layer.17.intermediate.v_dense.bias', 'encoder.layer.17.output.v_dense.weight', 'encoder.layer.17.output.v_dense.bias', 'encoder.layer.17.output.v_LayerNorm.weight', 'encoder.layer.17.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.intermediate.v_dense.weight', 'encoder.layer.19.intermediate.v_dense.bias', 'encoder.layer.19.output.v_dense.weight', 'encoder.layer.19.output.v_dense.bias', 'encoder.layer.19.output.v_LayerNorm.weight', 'encoder.layer.19.output.v_LayerNorm.bias', 'encoder.layer.20.attention_self.v_query.weight', 'encoder.layer.20.attention_self.v_query.bias', 'encoder.layer.20.attention_self.v_key.weight', 'encoder.layer.20.attention_self.v_key.bias', 'encoder.layer.20.attention_self.v_value.weight', 'encoder.layer.20.attention_self.v_value.bias', 'encoder.layer.20.attention_output.v_dense.weight', 'encoder.layer.20.attention_output.v_dense.bias', 'encoder.layer.20.attention_output.v_LayerNorm.weight', 'encoder.layer.20.attention_output.v_LayerNorm.bias', 'encoder.layer.21.intermediate.v_dense.weight', 'encoder.layer.21.intermediate.v_dense.bias', 'encoder.layer.21.output.v_dense.weight', 'encoder.layer.21.output.v_dense.bias', 'encoder.layer.21.output.v_LayerNorm.weight', 'encoder.layer.21.output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_visualbert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_visual_bert', 'output_path': 'hf_volta_models/ctrl_visual_bert_base'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_visualbert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_visual_bert', 'output_path': 'hf_volta_models/ctrl_visual_bert_base'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.20.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.20.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.20.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.20.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.20.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.20.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.20.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.20.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.20.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.20.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.21.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.21.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.21.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.21.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.21.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.21.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.18.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.18.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.18.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.18.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.18.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.18.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.18.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.18.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.18.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.18.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.19.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.19.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.19.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.19.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.19.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.19.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.16.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.16.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.16.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.16.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.16.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.16.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.16.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.16.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.16.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.16.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.17.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.17.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.17.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.17.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.17.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.17.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.12.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.12.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.12.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.12.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.12.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.12.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.12.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.12.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.12.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.12.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.13.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.13.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.13.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.13.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.13.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.13.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'embeddings.projection.weight', 'embeddings.projection.bias', 'embeddings.token_type_embeddings_visual.weight', 'embeddings.position_embeddings_visual.weight', 'encoder.layer.0.attention_self.v_query.weight', 'encoder.layer.0.attention_self.v_query.bias', 'encoder.layer.0.attention_self.v_key.weight', 'encoder.layer.0.attention_self.v_key.bias', 'encoder.layer.0.attention_self.v_value.weight', 'encoder.layer.0.attention_self.v_value.bias', 'encoder.layer.0.attention_output.v_dense.weight', 'encoder.layer.0.attention_output.v_dense.bias', 'encoder.layer.0.attention_output.v_LayerNorm.weight', 'encoder.layer.0.attention_output.v_LayerNorm.bias', 'encoder.layer.1.intermediate.v_dense.weight', 'encoder.layer.1.intermediate.v_dense.bias', 'encoder.layer.1.output.v_dense.weight', 'encoder.layer.1.output.v_dense.bias', 'encoder.layer.1.output.v_LayerNorm.weight', 'encoder.layer.1.output.v_LayerNorm.bias', 'encoder.layer.2.attention_self.v_query.weight', 'encoder.layer.2.attention_self.v_query.bias', 'encoder.layer.2.attention_self.v_key.weight', 'encoder.layer.2.attention_self.v_key.bias', 'encoder.layer.2.attention_self.v_value.weight', 'encoder.layer.2.attention_self.v_value.bias', 'encoder.layer.2.attention_output.v_dense.weight', 'encoder.layer.2.attention_output.v_dense.bias', 'encoder.layer.2.attention_output.v_LayerNorm.weight', 'encoder.layer.2.attention_output.v_LayerNorm.bias', 'encoder.layer.3.intermediate.v_dense.weight', 'encoder.layer.3.intermediate.v_dense.bias', 'encoder.layer.3.output.v_dense.weight', 'encoder.layer.3.output.v_dense.bias', 'encoder.layer.3.output.v_LayerNorm.weight', 'encoder.layer.3.output.v_LayerNorm.bias', 'encoder.layer.4.attention_self.v_query.weight', 'encoder.layer.4.attention_self.v_query.bias', 'encoder.layer.4.attention_self.v_key.weight', 'encoder.layer.4.attention_self.v_key.bias', 'encoder.layer.4.attention_self.v_value.weight', 'encoder.layer.4.attention_self.v_value.bias', 'encoder.layer.4.attention_output.v_dense.weight', 'encoder.layer.4.attention_output.v_dense.bias', 'encoder.layer.4.attention_output.v_LayerNorm.weight', 'encoder.layer.4.attention_output.v_LayerNorm.bias', 'encoder.layer.5.intermediate.v_dense.weight', 'encoder.layer.5.intermediate.v_dense.bias', 'encoder.layer.5.output.v_dense.weight', 'encoder.layer.5.output.v_dense.bias', 'encoder.layer.5.output.v_LayerNorm.weight', 'encoder.layer.5.output.v_LayerNorm.bias', 'encoder.layer.6.attention_self.v_query.weight', 'encoder.layer.6.attention_self.v_query.bias', 'encoder.layer.6.attention_self.v_key.weight', 'encoder.layer.6.attention_self.v_key.bias', 'encoder.layer.6.attention_self.v_value.weight', 'encoder.layer.6.attention_self.v_value.bias', 'encoder.layer.6.attention_output.v_dense.weight', 'encoder.layer.6.attention_output.v_dense.bias', 'encoder.layer.6.attention_output.v_LayerNorm.weight', 'encoder.layer.6.attention_output.v_LayerNorm.bias', 'encoder.layer.7.intermediate.v_dense.weight', 'encoder.layer.7.intermediate.v_dense.bias', 'encoder.layer.7.output.v_dense.weight', 'encoder.layer.7.output.v_dense.bias', 'encoder.layer.7.output.v_LayerNorm.weight', 'encoder.layer.7.output.v_LayerNorm.bias', 'encoder.layer.8.attention_self.v_query.weight', 'encoder.layer.8.attention_self.v_query.bias', 'encoder.layer.8.attention_self.v_key.weight', 'encoder.layer.8.attention_self.v_key.bias', 'encoder.layer.8.attention_self.v_value.weight', 'encoder.layer.8.attention_self.v_value.bias', 'encoder.layer.8.attention_output.v_dense.weight', 'encoder.layer.8.attention_output.v_dense.bias', 'encoder.layer.8.attention_output.v_LayerNorm.weight', 'encoder.layer.8.attention_output.v_LayerNorm.bias', 'encoder.layer.9.intermediate.v_dense.weight', 'encoder.layer.9.intermediate.v_dense.bias', 'encoder.layer.9.output.v_dense.weight', 'encoder.layer.9.output.v_dense.bias', 'encoder.layer.9.output.v_LayerNorm.weight', 'encoder.layer.9.output.v_LayerNorm.bias', 'encoder.layer.10.attention_self.v_query.weight', 'encoder.layer.10.attention_self.v_query.bias', 'encoder.layer.10.attention_self.v_key.weight', 'encoder.layer.10.attention_self.v_key.bias', 'encoder.layer.10.attention_self.v_value.weight', 'encoder.layer.10.attention_self.v_value.bias', 'encoder.layer.10.attention_output.v_dense.weight', 'encoder.layer.10.attention_output.v_dense.bias', 'encoder.layer.10.attention_output.v_LayerNorm.weight', 'encoder.layer.10.attention_output.v_LayerNorm.bias', 'encoder.layer.11.intermediate.v_dense.weight', 'encoder.layer.11.intermediate.v_dense.bias', 'encoder.layer.11.output.v_dense.weight', 'encoder.layer.11.output.v_dense.bias', 'encoder.layer.11.output.v_LayerNorm.weight', 'encoder.layer.11.output.v_LayerNorm.bias', 'encoder.layer.12.attention_self.v_query.weight', 'encoder.layer.12.attention_self.v_query.bias', 'encoder.layer.12.attention_self.v_key.weight', 'encoder.layer.12.attention_self.v_key.bias', 'encoder.layer.12.attention_self.v_value.weight', 'encoder.layer.12.attention_self.v_value.bias', 'encoder.layer.12.attention_output.v_dense.weight', 'encoder.layer.12.attention_output.v_dense.bias', 'encoder.layer.12.attention_output.v_LayerNorm.weight', 'encoder.layer.12.attention_output.v_LayerNorm.bias', 'encoder.layer.13.intermediate.v_dense.weight', 'encoder.layer.13.intermediate.v_dense.bias', 'encoder.layer.13.output.v_dense.weight', 'encoder.layer.13.output.v_dense.bias', 'encoder.layer.13.output.v_LayerNorm.weight', 'encoder.layer.13.output.v_LayerNorm.bias', 'encoder.layer.14.attention_self.v_query.weight', 'encoder.layer.14.attention_self.v_query.bias', 'encoder.layer.14.attention_self.v_key.weight', 'encoder.layer.14.attention_self.v_key.bias', 'encoder.layer.14.attention_self.v_value.weight', 'encoder.layer.14.attention_self.v_value.bias', 'encoder.layer.14.attention_output.v_dense.weight', 'encoder.layer.14.attention_output.v_dense.bias', 'encoder.layer.14.attention_output.v_LayerNorm.weight', 'encoder.layer.14.attention_output.v_LayerNorm.bias', 'encoder.layer.15.intermediate.v_dense.weight', 'encoder.layer.15.intermediate.v_dense.bias', 'encoder.layer.15.output.v_dense.weight', 'encoder.layer.15.output.v_dense.bias', 'encoder.layer.15.output.v_LayerNorm.weight', 'encoder.layer.15.output.v_LayerNorm.bias', 'encoder.layer.16.attention_self.v_query.weight', 'encoder.layer.16.attention_self.v_query.bias', 'encoder.layer.16.attention_self.v_key.weight', 'encoder.layer.16.attention_self.v_key.bias', 'encoder.layer.16.attention_self.v_value.weight', 'encoder.layer.16.attention_self.v_value.bias', 'encoder.layer.16.attention_output.v_dense.weight', 'encoder.layer.16.attention_output.v_dense.bias', 'encoder.layer.16.attention_output.v_LayerNorm.weight', 'encoder.layer.16.attention_output.v_LayerNorm.bias', 'encoder.layer.17.intermediate.v_dense.weight', 'encoder.layer.17.intermediate.v_dense.bias', 'encoder.layer.17.output.v_dense.weight', 'encoder.layer.17.output.v_dense.bias', 'encoder.layer.17.output.v_LayerNorm.weight', 'encoder.layer.17.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.intermediate.v_dense.weight', 'encoder.layer.19.intermediate.v_dense.bias', 'encoder.layer.19.output.v_dense.weight', 'encoder.layer.19.output.v_dense.bias', 'encoder.layer.19.output.v_LayerNorm.weight', 'encoder.layer.19.output.v_LayerNorm.bias', 'encoder.layer.20.attention_self.v_query.weight', 'encoder.layer.20.attention_self.v_query.bias', 'encoder.layer.20.attention_self.v_key.weight', 'encoder.layer.20.attention_self.v_key.bias', 'encoder.layer.20.attention_self.v_value.weight', 'encoder.layer.20.attention_self.v_value.bias', 'encoder.layer.20.attention_output.v_dense.weight', 'encoder.layer.20.attention_output.v_dense.bias', 'encoder.layer.20.attention_output.v_LayerNorm.weight', 'encoder.layer.20.attention_output.v_LayerNorm.bias', 'encoder.layer.21.intermediate.v_dense.weight', 'encoder.layer.21.intermediate.v_dense.bias', 'encoder.layer.21.output.v_dense.weight', 'encoder.layer.21.output.v_dense.bias', 'encoder.layer.21.output.v_LayerNorm.weight', 'encoder.layer.21.output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_vl-bert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_vl_bert', 'output_path': 'hf_volta_models/ctrl_vl_bert_base'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_vl-bert_base.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_vl_bert', 'output_path': 'hf_volta_models/ctrl_vl_bert_base'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.20.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.20.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.20.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.20.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.20.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.20.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.20.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.20.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.20.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.20.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.21.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.21.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.21.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.21.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.21.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.21.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.18.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.18.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.18.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.18.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.18.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.18.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.18.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.18.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.18.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.18.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.19.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.19.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.19.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.19.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.19.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.19.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.16.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.16.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.16.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.16.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.16.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.16.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.16.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.16.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.16.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.16.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.17.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.17.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.17.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.17.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.17.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.17.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.12.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.12.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.12.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.12.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.12.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.12.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.12.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.12.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.12.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.12.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.13.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.13.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.13.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.13.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.13.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.13.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'embeddings.obj_downsample.1.weight', 'embeddings.obj_downsample.1.bias', 'embeddings.object_linguistic_embeddings.weight', 'embeddings.object_mask_visual_embedding.weight', 'embeddings.end_embedding.weight', 'embeddings.visual_ln_text.weight', 'embeddings.visual_ln_text.bias', 'embeddings.visual_ln_object.weight', 'embeddings.visual_ln_object.bias', 'encoder.layer.0.attention_self.v_query.weight', 'encoder.layer.0.attention_self.v_query.bias', 'encoder.layer.0.attention_self.v_key.weight', 'encoder.layer.0.attention_self.v_key.bias', 'encoder.layer.0.attention_self.v_value.weight', 'encoder.layer.0.attention_self.v_value.bias', 'encoder.layer.0.attention_output.v_dense.weight', 'encoder.layer.0.attention_output.v_dense.bias', 'encoder.layer.0.attention_output.v_LayerNorm.weight', 'encoder.layer.0.attention_output.v_LayerNorm.bias', 'encoder.layer.1.intermediate.v_dense.weight', 'encoder.layer.1.intermediate.v_dense.bias', 'encoder.layer.1.output.v_dense.weight', 'encoder.layer.1.output.v_dense.bias', 'encoder.layer.1.output.v_LayerNorm.weight', 'encoder.layer.1.output.v_LayerNorm.bias', 'encoder.layer.2.attention_self.v_query.weight', 'encoder.layer.2.attention_self.v_query.bias', 'encoder.layer.2.attention_self.v_key.weight', 'encoder.layer.2.attention_self.v_key.bias', 'encoder.layer.2.attention_self.v_value.weight', 'encoder.layer.2.attention_self.v_value.bias', 'encoder.layer.2.attention_output.v_dense.weight', 'encoder.layer.2.attention_output.v_dense.bias', 'encoder.layer.2.attention_output.v_LayerNorm.weight', 'encoder.layer.2.attention_output.v_LayerNorm.bias', 'encoder.layer.3.intermediate.v_dense.weight', 'encoder.layer.3.intermediate.v_dense.bias', 'encoder.layer.3.output.v_dense.weight', 'encoder.layer.3.output.v_dense.bias', 'encoder.layer.3.output.v_LayerNorm.weight', 'encoder.layer.3.output.v_LayerNorm.bias', 'encoder.layer.4.attention_self.v_query.weight', 'encoder.layer.4.attention_self.v_query.bias', 'encoder.layer.4.attention_self.v_key.weight', 'encoder.layer.4.attention_self.v_key.bias', 'encoder.layer.4.attention_self.v_value.weight', 'encoder.layer.4.attention_self.v_value.bias', 'encoder.layer.4.attention_output.v_dense.weight', 'encoder.layer.4.attention_output.v_dense.bias', 'encoder.layer.4.attention_output.v_LayerNorm.weight', 'encoder.layer.4.attention_output.v_LayerNorm.bias', 'encoder.layer.5.intermediate.v_dense.weight', 'encoder.layer.5.intermediate.v_dense.bias', 'encoder.layer.5.output.v_dense.weight', 'encoder.layer.5.output.v_dense.bias', 'encoder.layer.5.output.v_LayerNorm.weight', 'encoder.layer.5.output.v_LayerNorm.bias', 'encoder.layer.6.attention_self.v_query.weight', 'encoder.layer.6.attention_self.v_query.bias', 'encoder.layer.6.attention_self.v_key.weight', 'encoder.layer.6.attention_self.v_key.bias', 'encoder.layer.6.attention_self.v_value.weight', 'encoder.layer.6.attention_self.v_value.bias', 'encoder.layer.6.attention_output.v_dense.weight', 'encoder.layer.6.attention_output.v_dense.bias', 'encoder.layer.6.attention_output.v_LayerNorm.weight', 'encoder.layer.6.attention_output.v_LayerNorm.bias', 'encoder.layer.7.intermediate.v_dense.weight', 'encoder.layer.7.intermediate.v_dense.bias', 'encoder.layer.7.output.v_dense.weight', 'encoder.layer.7.output.v_dense.bias', 'encoder.layer.7.output.v_LayerNorm.weight', 'encoder.layer.7.output.v_LayerNorm.bias', 'encoder.layer.8.attention_self.v_query.weight', 'encoder.layer.8.attention_self.v_query.bias', 'encoder.layer.8.attention_self.v_key.weight', 'encoder.layer.8.attention_self.v_key.bias', 'encoder.layer.8.attention_self.v_value.weight', 'encoder.layer.8.attention_self.v_value.bias', 'encoder.layer.8.attention_output.v_dense.weight', 'encoder.layer.8.attention_output.v_dense.bias', 'encoder.layer.8.attention_output.v_LayerNorm.weight', 'encoder.layer.8.attention_output.v_LayerNorm.bias', 'encoder.layer.9.intermediate.v_dense.weight', 'encoder.layer.9.intermediate.v_dense.bias', 'encoder.layer.9.output.v_dense.weight', 'encoder.layer.9.output.v_dense.bias', 'encoder.layer.9.output.v_LayerNorm.weight', 'encoder.layer.9.output.v_LayerNorm.bias', 'encoder.layer.10.attention_self.v_query.weight', 'encoder.layer.10.attention_self.v_query.bias', 'encoder.layer.10.attention_self.v_key.weight', 'encoder.layer.10.attention_self.v_key.bias', 'encoder.layer.10.attention_self.v_value.weight', 'encoder.layer.10.attention_self.v_value.bias', 'encoder.layer.10.attention_output.v_dense.weight', 'encoder.layer.10.attention_output.v_dense.bias', 'encoder.layer.10.attention_output.v_LayerNorm.weight', 'encoder.layer.10.attention_output.v_LayerNorm.bias', 'encoder.layer.11.intermediate.v_dense.weight', 'encoder.layer.11.intermediate.v_dense.bias', 'encoder.layer.11.output.v_dense.weight', 'encoder.layer.11.output.v_dense.bias', 'encoder.layer.11.output.v_LayerNorm.weight', 'encoder.layer.11.output.v_LayerNorm.bias', 'encoder.layer.12.attention_self.v_query.weight', 'encoder.layer.12.attention_self.v_query.bias', 'encoder.layer.12.attention_self.v_key.weight', 'encoder.layer.12.attention_self.v_key.bias', 'encoder.layer.12.attention_self.v_value.weight', 'encoder.layer.12.attention_self.v_value.bias', 'encoder.layer.12.attention_output.v_dense.weight', 'encoder.layer.12.attention_output.v_dense.bias', 'encoder.layer.12.attention_output.v_LayerNorm.weight', 'encoder.layer.12.attention_output.v_LayerNorm.bias', 'encoder.layer.13.intermediate.v_dense.weight', 'encoder.layer.13.intermediate.v_dense.bias', 'encoder.layer.13.output.v_dense.weight', 'encoder.layer.13.output.v_dense.bias', 'encoder.layer.13.output.v_LayerNorm.weight', 'encoder.layer.13.output.v_LayerNorm.bias', 'encoder.layer.14.attention_self.v_query.weight', 'encoder.layer.14.attention_self.v_query.bias', 'encoder.layer.14.attention_self.v_key.weight', 'encoder.layer.14.attention_self.v_key.bias', 'encoder.layer.14.attention_self.v_value.weight', 'encoder.layer.14.attention_self.v_value.bias', 'encoder.layer.14.attention_output.v_dense.weight', 'encoder.layer.14.attention_output.v_dense.bias', 'encoder.layer.14.attention_output.v_LayerNorm.weight', 'encoder.layer.14.attention_output.v_LayerNorm.bias', 'encoder.layer.15.intermediate.v_dense.weight', 'encoder.layer.15.intermediate.v_dense.bias', 'encoder.layer.15.output.v_dense.weight', 'encoder.layer.15.output.v_dense.bias', 'encoder.layer.15.output.v_LayerNorm.weight', 'encoder.layer.15.output.v_LayerNorm.bias', 'encoder.layer.16.attention_self.v_query.weight', 'encoder.layer.16.attention_self.v_query.bias', 'encoder.layer.16.attention_self.v_key.weight', 'encoder.layer.16.attention_self.v_key.bias', 'encoder.layer.16.attention_self.v_value.weight', 'encoder.layer.16.attention_self.v_value.bias', 'encoder.layer.16.attention_output.v_dense.weight', 'encoder.layer.16.attention_output.v_dense.bias', 'encoder.layer.16.attention_output.v_LayerNorm.weight', 'encoder.layer.16.attention_output.v_LayerNorm.bias', 'encoder.layer.17.intermediate.v_dense.weight', 'encoder.layer.17.intermediate.v_dense.bias', 'encoder.layer.17.output.v_dense.weight', 'encoder.layer.17.output.v_dense.bias', 'encoder.layer.17.output.v_LayerNorm.weight', 'encoder.layer.17.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.intermediate.v_dense.weight', 'encoder.layer.19.intermediate.v_dense.bias', 'encoder.layer.19.output.v_dense.weight', 'encoder.layer.19.output.v_dense.bias', 'encoder.layer.19.output.v_LayerNorm.weight', 'encoder.layer.19.output.v_LayerNorm.bias', 'encoder.layer.20.attention_self.v_query.weight', 'encoder.layer.20.attention_self.v_query.bias', 'encoder.layer.20.attention_self.v_key.weight', 'encoder.layer.20.attention_self.v_key.bias', 'encoder.layer.20.attention_self.v_value.weight', 'encoder.layer.20.attention_self.v_value.bias', 'encoder.layer.20.attention_output.v_dense.weight', 'encoder.layer.20.attention_output.v_dense.bias', 'encoder.layer.20.attention_output.v_LayerNorm.weight', 'encoder.layer.20.attention_output.v_LayerNorm.bias', 'encoder.layer.21.intermediate.v_dense.weight', 'encoder.layer.21.intermediate.v_dense.bias', 'encoder.layer.21.output.v_dense.weight', 'encoder.layer.21.output.v_dense.bias', 'encoder.layer.21.output.v_LayerNorm.weight', 'encoder.layer.21.output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    print('compile', target)\n",
    "    compile_model(dummy_imgfeats=dummy_imgfeats, **target)\n",
    "    print('reinit', target)\n",
    "    make_reinit_model(target['output_path'], target['output_path']+'_reinit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the new version of lxmert\n",
    "dummy_imgfeats = {\n",
    "    'path': 'volta/data/glue/glue_imgfeats.lmdb',\n",
    "    'key': 'black_224',\n",
    "}\n",
    "targets = [\n",
    "    {'config_path':'volta/config/ctrl_lxmert.json',\n",
    "         'weight_path':'volta/checkpoints/distributed/ctrl_lxmert_new', \n",
    "         'output_path':'hf_volta_models/ctrl_lxmert_base_new'},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile {'config_path': 'volta/config/ctrl_lxmert.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_lxmert_new', 'output_path': 'hf_volta_models/ctrl_lxmert_base_new'}\n",
      "start_prefix bert. model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['bert.dummy_input_imgs', 'bert.dummy_image_loc']\n",
      "reinit {'config_path': 'volta/config/ctrl_lxmert.json', 'weight_path': 'volta/checkpoints/distributed/ctrl_lxmert_new', 'output_path': 'hf_volta_models/ctrl_lxmert_base_new'}\n",
      "weight mapping encoder.layer.11.attention.self.query.weight -> encoder.layer.25.attention_self.query.weight\n",
      "weight mapping encoder.layer.11.attention.self.query.bias -> encoder.layer.25.attention_self.query.bias\n",
      "weight mapping encoder.layer.11.attention.self.key.weight -> encoder.layer.25.attention_self.key.weight\n",
      "weight mapping encoder.layer.11.attention.self.key.bias -> encoder.layer.25.attention_self.key.bias\n",
      "weight mapping encoder.layer.11.attention.self.value.weight -> encoder.layer.25.attention_self.value.weight\n",
      "weight mapping encoder.layer.11.attention.self.value.bias -> encoder.layer.25.attention_self.value.bias\n",
      "weight mapping encoder.layer.11.attention.output.dense.weight -> encoder.layer.25.attention_output.dense.weight\n",
      "weight mapping encoder.layer.11.attention.output.dense.bias -> encoder.layer.25.attention_output.dense.bias\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.weight -> encoder.layer.25.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.attention.output.LayerNorm.bias -> encoder.layer.25.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.11.intermediate.dense.weight -> encoder.layer.26.intermediate.dense.weight\n",
      "weight mapping encoder.layer.11.intermediate.dense.bias -> encoder.layer.26.intermediate.dense.bias\n",
      "weight mapping encoder.layer.11.output.dense.weight -> encoder.layer.26.output.dense.weight\n",
      "weight mapping encoder.layer.11.output.dense.bias -> encoder.layer.26.output.dense.bias\n",
      "weight mapping encoder.layer.11.output.LayerNorm.weight -> encoder.layer.26.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.11.output.LayerNorm.bias -> encoder.layer.26.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.attention.self.query.weight -> encoder.layer.22.attention_self.query.weight\n",
      "weight mapping encoder.layer.10.attention.self.query.bias -> encoder.layer.22.attention_self.query.bias\n",
      "weight mapping encoder.layer.10.attention.self.key.weight -> encoder.layer.22.attention_self.key.weight\n",
      "weight mapping encoder.layer.10.attention.self.key.bias -> encoder.layer.22.attention_self.key.bias\n",
      "weight mapping encoder.layer.10.attention.self.value.weight -> encoder.layer.22.attention_self.value.weight\n",
      "weight mapping encoder.layer.10.attention.self.value.bias -> encoder.layer.22.attention_self.value.bias\n",
      "weight mapping encoder.layer.10.attention.output.dense.weight -> encoder.layer.22.attention_output.dense.weight\n",
      "weight mapping encoder.layer.10.attention.output.dense.bias -> encoder.layer.22.attention_output.dense.bias\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.weight -> encoder.layer.22.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.attention.output.LayerNorm.bias -> encoder.layer.22.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.10.intermediate.dense.weight -> encoder.layer.23.intermediate.dense.weight\n",
      "weight mapping encoder.layer.10.intermediate.dense.bias -> encoder.layer.23.intermediate.dense.bias\n",
      "weight mapping encoder.layer.10.output.dense.weight -> encoder.layer.23.output.dense.weight\n",
      "weight mapping encoder.layer.10.output.dense.bias -> encoder.layer.23.output.dense.bias\n",
      "weight mapping encoder.layer.10.output.LayerNorm.weight -> encoder.layer.23.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.10.output.LayerNorm.bias -> encoder.layer.23.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.attention.self.query.weight -> encoder.layer.19.attention_self.query.weight\n",
      "weight mapping encoder.layer.9.attention.self.query.bias -> encoder.layer.19.attention_self.query.bias\n",
      "weight mapping encoder.layer.9.attention.self.key.weight -> encoder.layer.19.attention_self.key.weight\n",
      "weight mapping encoder.layer.9.attention.self.key.bias -> encoder.layer.19.attention_self.key.bias\n",
      "weight mapping encoder.layer.9.attention.self.value.weight -> encoder.layer.19.attention_self.value.weight\n",
      "weight mapping encoder.layer.9.attention.self.value.bias -> encoder.layer.19.attention_self.value.bias\n",
      "weight mapping encoder.layer.9.attention.output.dense.weight -> encoder.layer.19.attention_output.dense.weight\n",
      "weight mapping encoder.layer.9.attention.output.dense.bias -> encoder.layer.19.attention_output.dense.bias\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.weight -> encoder.layer.19.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.attention.output.LayerNorm.bias -> encoder.layer.19.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.9.intermediate.dense.weight -> encoder.layer.20.intermediate.dense.weight\n",
      "weight mapping encoder.layer.9.intermediate.dense.bias -> encoder.layer.20.intermediate.dense.bias\n",
      "weight mapping encoder.layer.9.output.dense.weight -> encoder.layer.20.output.dense.weight\n",
      "weight mapping encoder.layer.9.output.dense.bias -> encoder.layer.20.output.dense.bias\n",
      "weight mapping encoder.layer.9.output.LayerNorm.weight -> encoder.layer.20.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.9.output.LayerNorm.bias -> encoder.layer.20.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.attention.self.query.weight -> encoder.layer.16.attention_self.query.weight\n",
      "weight mapping encoder.layer.8.attention.self.query.bias -> encoder.layer.16.attention_self.query.bias\n",
      "weight mapping encoder.layer.8.attention.self.key.weight -> encoder.layer.16.attention_self.key.weight\n",
      "weight mapping encoder.layer.8.attention.self.key.bias -> encoder.layer.16.attention_self.key.bias\n",
      "weight mapping encoder.layer.8.attention.self.value.weight -> encoder.layer.16.attention_self.value.weight\n",
      "weight mapping encoder.layer.8.attention.self.value.bias -> encoder.layer.16.attention_self.value.bias\n",
      "weight mapping encoder.layer.8.attention.output.dense.weight -> encoder.layer.16.attention_output.dense.weight\n",
      "weight mapping encoder.layer.8.attention.output.dense.bias -> encoder.layer.16.attention_output.dense.bias\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.weight -> encoder.layer.16.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.attention.output.LayerNorm.bias -> encoder.layer.16.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.8.intermediate.dense.weight -> encoder.layer.17.intermediate.dense.weight\n",
      "weight mapping encoder.layer.8.intermediate.dense.bias -> encoder.layer.17.intermediate.dense.bias\n",
      "weight mapping encoder.layer.8.output.dense.weight -> encoder.layer.17.output.dense.weight\n",
      "weight mapping encoder.layer.8.output.dense.bias -> encoder.layer.17.output.dense.bias\n",
      "weight mapping encoder.layer.8.output.LayerNorm.weight -> encoder.layer.17.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.8.output.LayerNorm.bias -> encoder.layer.17.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.attention.self.query.weight -> encoder.layer.14.attention_self.query.weight\n",
      "weight mapping encoder.layer.7.attention.self.query.bias -> encoder.layer.14.attention_self.query.bias\n",
      "weight mapping encoder.layer.7.attention.self.key.weight -> encoder.layer.14.attention_self.key.weight\n",
      "weight mapping encoder.layer.7.attention.self.key.bias -> encoder.layer.14.attention_self.key.bias\n",
      "weight mapping encoder.layer.7.attention.self.value.weight -> encoder.layer.14.attention_self.value.weight\n",
      "weight mapping encoder.layer.7.attention.self.value.bias -> encoder.layer.14.attention_self.value.bias\n",
      "weight mapping encoder.layer.7.attention.output.dense.weight -> encoder.layer.14.attention_output.dense.weight\n",
      "weight mapping encoder.layer.7.attention.output.dense.bias -> encoder.layer.14.attention_output.dense.bias\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.weight -> encoder.layer.14.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.attention.output.LayerNorm.bias -> encoder.layer.14.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.7.intermediate.dense.weight -> encoder.layer.15.intermediate.dense.weight\n",
      "weight mapping encoder.layer.7.intermediate.dense.bias -> encoder.layer.15.intermediate.dense.bias\n",
      "weight mapping encoder.layer.7.output.dense.weight -> encoder.layer.15.output.dense.weight\n",
      "weight mapping encoder.layer.7.output.dense.bias -> encoder.layer.15.output.dense.bias\n",
      "weight mapping encoder.layer.7.output.LayerNorm.weight -> encoder.layer.15.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.7.output.LayerNorm.bias -> encoder.layer.15.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.attention.self.query.weight -> encoder.layer.12.attention_self.query.weight\n",
      "weight mapping encoder.layer.6.attention.self.query.bias -> encoder.layer.12.attention_self.query.bias\n",
      "weight mapping encoder.layer.6.attention.self.key.weight -> encoder.layer.12.attention_self.key.weight\n",
      "weight mapping encoder.layer.6.attention.self.key.bias -> encoder.layer.12.attention_self.key.bias\n",
      "weight mapping encoder.layer.6.attention.self.value.weight -> encoder.layer.12.attention_self.value.weight\n",
      "weight mapping encoder.layer.6.attention.self.value.bias -> encoder.layer.12.attention_self.value.bias\n",
      "weight mapping encoder.layer.6.attention.output.dense.weight -> encoder.layer.12.attention_output.dense.weight\n",
      "weight mapping encoder.layer.6.attention.output.dense.bias -> encoder.layer.12.attention_output.dense.bias\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.weight -> encoder.layer.12.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.attention.output.LayerNorm.bias -> encoder.layer.12.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.6.intermediate.dense.weight -> encoder.layer.13.intermediate.dense.weight\n",
      "weight mapping encoder.layer.6.intermediate.dense.bias -> encoder.layer.13.intermediate.dense.bias\n",
      "weight mapping encoder.layer.6.output.dense.weight -> encoder.layer.13.output.dense.weight\n",
      "weight mapping encoder.layer.6.output.dense.bias -> encoder.layer.13.output.dense.bias\n",
      "weight mapping encoder.layer.6.output.LayerNorm.weight -> encoder.layer.13.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.6.output.LayerNorm.bias -> encoder.layer.13.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.attention.self.query.weight -> encoder.layer.10.attention_self.query.weight\n",
      "weight mapping encoder.layer.5.attention.self.query.bias -> encoder.layer.10.attention_self.query.bias\n",
      "weight mapping encoder.layer.5.attention.self.key.weight -> encoder.layer.10.attention_self.key.weight\n",
      "weight mapping encoder.layer.5.attention.self.key.bias -> encoder.layer.10.attention_self.key.bias\n",
      "weight mapping encoder.layer.5.attention.self.value.weight -> encoder.layer.10.attention_self.value.weight\n",
      "weight mapping encoder.layer.5.attention.self.value.bias -> encoder.layer.10.attention_self.value.bias\n",
      "weight mapping encoder.layer.5.attention.output.dense.weight -> encoder.layer.10.attention_output.dense.weight\n",
      "weight mapping encoder.layer.5.attention.output.dense.bias -> encoder.layer.10.attention_output.dense.bias\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.weight -> encoder.layer.10.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.attention.output.LayerNorm.bias -> encoder.layer.10.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.5.intermediate.dense.weight -> encoder.layer.11.intermediate.dense.weight\n",
      "weight mapping encoder.layer.5.intermediate.dense.bias -> encoder.layer.11.intermediate.dense.bias\n",
      "weight mapping encoder.layer.5.output.dense.weight -> encoder.layer.11.output.dense.weight\n",
      "weight mapping encoder.layer.5.output.dense.bias -> encoder.layer.11.output.dense.bias\n",
      "weight mapping encoder.layer.5.output.LayerNorm.weight -> encoder.layer.11.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.5.output.LayerNorm.bias -> encoder.layer.11.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.attention.self.query.weight -> encoder.layer.8.attention_self.query.weight\n",
      "weight mapping encoder.layer.4.attention.self.query.bias -> encoder.layer.8.attention_self.query.bias\n",
      "weight mapping encoder.layer.4.attention.self.key.weight -> encoder.layer.8.attention_self.key.weight\n",
      "weight mapping encoder.layer.4.attention.self.key.bias -> encoder.layer.8.attention_self.key.bias\n",
      "weight mapping encoder.layer.4.attention.self.value.weight -> encoder.layer.8.attention_self.value.weight\n",
      "weight mapping encoder.layer.4.attention.self.value.bias -> encoder.layer.8.attention_self.value.bias\n",
      "weight mapping encoder.layer.4.attention.output.dense.weight -> encoder.layer.8.attention_output.dense.weight\n",
      "weight mapping encoder.layer.4.attention.output.dense.bias -> encoder.layer.8.attention_output.dense.bias\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.weight -> encoder.layer.8.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.attention.output.LayerNorm.bias -> encoder.layer.8.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.4.intermediate.dense.weight -> encoder.layer.9.intermediate.dense.weight\n",
      "weight mapping encoder.layer.4.intermediate.dense.bias -> encoder.layer.9.intermediate.dense.bias\n",
      "weight mapping encoder.layer.4.output.dense.weight -> encoder.layer.9.output.dense.weight\n",
      "weight mapping encoder.layer.4.output.dense.bias -> encoder.layer.9.output.dense.bias\n",
      "weight mapping encoder.layer.4.output.LayerNorm.weight -> encoder.layer.9.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.4.output.LayerNorm.bias -> encoder.layer.9.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.attention.self.query.weight -> encoder.layer.6.attention_self.query.weight\n",
      "weight mapping encoder.layer.3.attention.self.query.bias -> encoder.layer.6.attention_self.query.bias\n",
      "weight mapping encoder.layer.3.attention.self.key.weight -> encoder.layer.6.attention_self.key.weight\n",
      "weight mapping encoder.layer.3.attention.self.key.bias -> encoder.layer.6.attention_self.key.bias\n",
      "weight mapping encoder.layer.3.attention.self.value.weight -> encoder.layer.6.attention_self.value.weight\n",
      "weight mapping encoder.layer.3.attention.self.value.bias -> encoder.layer.6.attention_self.value.bias\n",
      "weight mapping encoder.layer.3.attention.output.dense.weight -> encoder.layer.6.attention_output.dense.weight\n",
      "weight mapping encoder.layer.3.attention.output.dense.bias -> encoder.layer.6.attention_output.dense.bias\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.weight -> encoder.layer.6.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.attention.output.LayerNorm.bias -> encoder.layer.6.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.3.intermediate.dense.weight -> encoder.layer.7.intermediate.dense.weight\n",
      "weight mapping encoder.layer.3.intermediate.dense.bias -> encoder.layer.7.intermediate.dense.bias\n",
      "weight mapping encoder.layer.3.output.dense.weight -> encoder.layer.7.output.dense.weight\n",
      "weight mapping encoder.layer.3.output.dense.bias -> encoder.layer.7.output.dense.bias\n",
      "weight mapping encoder.layer.3.output.LayerNorm.weight -> encoder.layer.7.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.3.output.LayerNorm.bias -> encoder.layer.7.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.attention.self.query.weight -> encoder.layer.4.attention_self.query.weight\n",
      "weight mapping encoder.layer.2.attention.self.query.bias -> encoder.layer.4.attention_self.query.bias\n",
      "weight mapping encoder.layer.2.attention.self.key.weight -> encoder.layer.4.attention_self.key.weight\n",
      "weight mapping encoder.layer.2.attention.self.key.bias -> encoder.layer.4.attention_self.key.bias\n",
      "weight mapping encoder.layer.2.attention.self.value.weight -> encoder.layer.4.attention_self.value.weight\n",
      "weight mapping encoder.layer.2.attention.self.value.bias -> encoder.layer.4.attention_self.value.bias\n",
      "weight mapping encoder.layer.2.attention.output.dense.weight -> encoder.layer.4.attention_output.dense.weight\n",
      "weight mapping encoder.layer.2.attention.output.dense.bias -> encoder.layer.4.attention_output.dense.bias\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.weight -> encoder.layer.4.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.attention.output.LayerNorm.bias -> encoder.layer.4.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.2.intermediate.dense.weight -> encoder.layer.5.intermediate.dense.weight\n",
      "weight mapping encoder.layer.2.intermediate.dense.bias -> encoder.layer.5.intermediate.dense.bias\n",
      "weight mapping encoder.layer.2.output.dense.weight -> encoder.layer.5.output.dense.weight\n",
      "weight mapping encoder.layer.2.output.dense.bias -> encoder.layer.5.output.dense.bias\n",
      "weight mapping encoder.layer.2.output.LayerNorm.weight -> encoder.layer.5.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.2.output.LayerNorm.bias -> encoder.layer.5.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.attention.self.query.weight -> encoder.layer.2.attention_self.query.weight\n",
      "weight mapping encoder.layer.1.attention.self.query.bias -> encoder.layer.2.attention_self.query.bias\n",
      "weight mapping encoder.layer.1.attention.self.key.weight -> encoder.layer.2.attention_self.key.weight\n",
      "weight mapping encoder.layer.1.attention.self.key.bias -> encoder.layer.2.attention_self.key.bias\n",
      "weight mapping encoder.layer.1.attention.self.value.weight -> encoder.layer.2.attention_self.value.weight\n",
      "weight mapping encoder.layer.1.attention.self.value.bias -> encoder.layer.2.attention_self.value.bias\n",
      "weight mapping encoder.layer.1.attention.output.dense.weight -> encoder.layer.2.attention_output.dense.weight\n",
      "weight mapping encoder.layer.1.attention.output.dense.bias -> encoder.layer.2.attention_output.dense.bias\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.weight -> encoder.layer.2.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.attention.output.LayerNorm.bias -> encoder.layer.2.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.1.intermediate.dense.weight -> encoder.layer.3.intermediate.dense.weight\n",
      "weight mapping encoder.layer.1.intermediate.dense.bias -> encoder.layer.3.intermediate.dense.bias\n",
      "weight mapping encoder.layer.1.output.dense.weight -> encoder.layer.3.output.dense.weight\n",
      "weight mapping encoder.layer.1.output.dense.bias -> encoder.layer.3.output.dense.bias\n",
      "weight mapping encoder.layer.1.output.LayerNorm.weight -> encoder.layer.3.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.1.output.LayerNorm.bias -> encoder.layer.3.output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.attention.self.query.weight -> encoder.layer.0.attention_self.query.weight\n",
      "weight mapping encoder.layer.0.attention.self.query.bias -> encoder.layer.0.attention_self.query.bias\n",
      "weight mapping encoder.layer.0.attention.self.key.weight -> encoder.layer.0.attention_self.key.weight\n",
      "weight mapping encoder.layer.0.attention.self.key.bias -> encoder.layer.0.attention_self.key.bias\n",
      "weight mapping encoder.layer.0.attention.self.value.weight -> encoder.layer.0.attention_self.value.weight\n",
      "weight mapping encoder.layer.0.attention.self.value.bias -> encoder.layer.0.attention_self.value.bias\n",
      "weight mapping encoder.layer.0.attention.output.dense.weight -> encoder.layer.0.attention_output.dense.weight\n",
      "weight mapping encoder.layer.0.attention.output.dense.bias -> encoder.layer.0.attention_output.dense.bias\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.weight -> encoder.layer.0.attention_output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.attention.output.LayerNorm.bias -> encoder.layer.0.attention_output.LayerNorm.bias\n",
      "weight mapping encoder.layer.0.intermediate.dense.weight -> encoder.layer.1.intermediate.dense.weight\n",
      "weight mapping encoder.layer.0.intermediate.dense.bias -> encoder.layer.1.intermediate.dense.bias\n",
      "weight mapping encoder.layer.0.output.dense.weight -> encoder.layer.1.output.dense.weight\n",
      "weight mapping encoder.layer.0.output.dense.bias -> encoder.layer.1.output.dense.bias\n",
      "weight mapping encoder.layer.0.output.LayerNorm.weight -> encoder.layer.1.output.LayerNorm.weight\n",
      "weight mapping encoder.layer.0.output.LayerNorm.bias -> encoder.layer.1.output.LayerNorm.bias\n",
      "start_prefix  model_to_load VoltaModel\n",
      "Weights of VoltaModel not initialized from pretrained model: ['dummy_input_imgs', 'dummy_image_loc', 'v_embeddings.image_embeddings.weight', 'v_embeddings.image_embeddings.bias', 'v_embeddings.image_location_embeddings.weight', 'v_embeddings.image_location_embeddings.bias', 'v_embeddings.ImgLayerNorm.weight', 'v_embeddings.ImgLayerNorm.bias', 'v_embeddings.LocLayerNorm.weight', 'v_embeddings.LocLayerNorm.bias', 'encoder.layer.0.attention_self.v_query.weight', 'encoder.layer.0.attention_self.v_query.bias', 'encoder.layer.0.attention_self.v_key.weight', 'encoder.layer.0.attention_self.v_key.bias', 'encoder.layer.0.attention_self.v_value.weight', 'encoder.layer.0.attention_self.v_value.bias', 'encoder.layer.0.attention_output.v_dense.weight', 'encoder.layer.0.attention_output.v_dense.bias', 'encoder.layer.0.attention_output.v_LayerNorm.weight', 'encoder.layer.0.attention_output.v_LayerNorm.bias', 'encoder.layer.1.intermediate.v_dense.weight', 'encoder.layer.1.intermediate.v_dense.bias', 'encoder.layer.1.output.v_dense.weight', 'encoder.layer.1.output.v_dense.bias', 'encoder.layer.1.output.v_LayerNorm.weight', 'encoder.layer.1.output.v_LayerNorm.bias', 'encoder.layer.2.attention_self.v_query.weight', 'encoder.layer.2.attention_self.v_query.bias', 'encoder.layer.2.attention_self.v_key.weight', 'encoder.layer.2.attention_self.v_key.bias', 'encoder.layer.2.attention_self.v_value.weight', 'encoder.layer.2.attention_self.v_value.bias', 'encoder.layer.2.attention_output.v_dense.weight', 'encoder.layer.2.attention_output.v_dense.bias', 'encoder.layer.2.attention_output.v_LayerNorm.weight', 'encoder.layer.2.attention_output.v_LayerNorm.bias', 'encoder.layer.3.intermediate.v_dense.weight', 'encoder.layer.3.intermediate.v_dense.bias', 'encoder.layer.3.output.v_dense.weight', 'encoder.layer.3.output.v_dense.bias', 'encoder.layer.3.output.v_LayerNorm.weight', 'encoder.layer.3.output.v_LayerNorm.bias', 'encoder.layer.4.attention_self.v_query.weight', 'encoder.layer.4.attention_self.v_query.bias', 'encoder.layer.4.attention_self.v_key.weight', 'encoder.layer.4.attention_self.v_key.bias', 'encoder.layer.4.attention_self.v_value.weight', 'encoder.layer.4.attention_self.v_value.bias', 'encoder.layer.4.attention_output.v_dense.weight', 'encoder.layer.4.attention_output.v_dense.bias', 'encoder.layer.4.attention_output.v_LayerNorm.weight', 'encoder.layer.4.attention_output.v_LayerNorm.bias', 'encoder.layer.5.intermediate.v_dense.weight', 'encoder.layer.5.intermediate.v_dense.bias', 'encoder.layer.5.output.v_dense.weight', 'encoder.layer.5.output.v_dense.bias', 'encoder.layer.5.output.v_LayerNorm.weight', 'encoder.layer.5.output.v_LayerNorm.bias', 'encoder.layer.6.attention_self.v_query.weight', 'encoder.layer.6.attention_self.v_query.bias', 'encoder.layer.6.attention_self.v_key.weight', 'encoder.layer.6.attention_self.v_key.bias', 'encoder.layer.6.attention_self.v_value.weight', 'encoder.layer.6.attention_self.v_value.bias', 'encoder.layer.6.attention_output.v_dense.weight', 'encoder.layer.6.attention_output.v_dense.bias', 'encoder.layer.6.attention_output.v_LayerNorm.weight', 'encoder.layer.6.attention_output.v_LayerNorm.bias', 'encoder.layer.7.intermediate.v_dense.weight', 'encoder.layer.7.intermediate.v_dense.bias', 'encoder.layer.7.output.v_dense.weight', 'encoder.layer.7.output.v_dense.bias', 'encoder.layer.7.output.v_LayerNorm.weight', 'encoder.layer.7.output.v_LayerNorm.bias', 'encoder.layer.8.attention_self.v_query.weight', 'encoder.layer.8.attention_self.v_query.bias', 'encoder.layer.8.attention_self.v_key.weight', 'encoder.layer.8.attention_self.v_key.bias', 'encoder.layer.8.attention_self.v_value.weight', 'encoder.layer.8.attention_self.v_value.bias', 'encoder.layer.8.attention_output.v_dense.weight', 'encoder.layer.8.attention_output.v_dense.bias', 'encoder.layer.8.attention_output.v_LayerNorm.weight', 'encoder.layer.8.attention_output.v_LayerNorm.bias', 'encoder.layer.9.intermediate.v_dense.weight', 'encoder.layer.9.intermediate.v_dense.bias', 'encoder.layer.9.output.v_dense.weight', 'encoder.layer.9.output.v_dense.bias', 'encoder.layer.9.output.v_LayerNorm.weight', 'encoder.layer.9.output.v_LayerNorm.bias', 'encoder.layer.18.attention_self.query.weight', 'encoder.layer.18.attention_self.query.bias', 'encoder.layer.18.attention_self.key.weight', 'encoder.layer.18.attention_self.key.bias', 'encoder.layer.18.attention_self.value.weight', 'encoder.layer.18.attention_self.value.bias', 'encoder.layer.18.attention_self.v_query.weight', 'encoder.layer.18.attention_self.v_query.bias', 'encoder.layer.18.attention_self.v_key.weight', 'encoder.layer.18.attention_self.v_key.bias', 'encoder.layer.18.attention_self.v_value.weight', 'encoder.layer.18.attention_self.v_value.bias', 'encoder.layer.18.attention_output.dense.weight', 'encoder.layer.18.attention_output.dense.bias', 'encoder.layer.18.attention_output.LayerNorm.weight', 'encoder.layer.18.attention_output.LayerNorm.bias', 'encoder.layer.18.attention_output.v_dense.weight', 'encoder.layer.18.attention_output.v_dense.bias', 'encoder.layer.18.attention_output.v_LayerNorm.weight', 'encoder.layer.18.attention_output.v_LayerNorm.bias', 'encoder.layer.19.attention_self.v_query.weight', 'encoder.layer.19.attention_self.v_query.bias', 'encoder.layer.19.attention_self.v_key.weight', 'encoder.layer.19.attention_self.v_key.bias', 'encoder.layer.19.attention_self.v_value.weight', 'encoder.layer.19.attention_self.v_value.bias', 'encoder.layer.19.attention_output.v_dense.weight', 'encoder.layer.19.attention_output.v_dense.bias', 'encoder.layer.19.attention_output.v_LayerNorm.weight', 'encoder.layer.19.attention_output.v_LayerNorm.bias', 'encoder.layer.20.intermediate.v_dense.weight', 'encoder.layer.20.intermediate.v_dense.bias', 'encoder.layer.20.output.v_dense.weight', 'encoder.layer.20.output.v_dense.bias', 'encoder.layer.20.output.v_LayerNorm.weight', 'encoder.layer.20.output.v_LayerNorm.bias', 'encoder.layer.21.attention_self.query.weight', 'encoder.layer.21.attention_self.query.bias', 'encoder.layer.21.attention_self.key.weight', 'encoder.layer.21.attention_self.key.bias', 'encoder.layer.21.attention_self.value.weight', 'encoder.layer.21.attention_self.value.bias', 'encoder.layer.21.attention_self.v_query.weight', 'encoder.layer.21.attention_self.v_query.bias', 'encoder.layer.21.attention_self.v_key.weight', 'encoder.layer.21.attention_self.v_key.bias', 'encoder.layer.21.attention_self.v_value.weight', 'encoder.layer.21.attention_self.v_value.bias', 'encoder.layer.21.attention_output.dense.weight', 'encoder.layer.21.attention_output.dense.bias', 'encoder.layer.21.attention_output.LayerNorm.weight', 'encoder.layer.21.attention_output.LayerNorm.bias', 'encoder.layer.21.attention_output.v_dense.weight', 'encoder.layer.21.attention_output.v_dense.bias', 'encoder.layer.21.attention_output.v_LayerNorm.weight', 'encoder.layer.21.attention_output.v_LayerNorm.bias', 'encoder.layer.22.attention_self.v_query.weight', 'encoder.layer.22.attention_self.v_query.bias', 'encoder.layer.22.attention_self.v_key.weight', 'encoder.layer.22.attention_self.v_key.bias', 'encoder.layer.22.attention_self.v_value.weight', 'encoder.layer.22.attention_self.v_value.bias', 'encoder.layer.22.attention_output.v_dense.weight', 'encoder.layer.22.attention_output.v_dense.bias', 'encoder.layer.22.attention_output.v_LayerNorm.weight', 'encoder.layer.22.attention_output.v_LayerNorm.bias', 'encoder.layer.23.intermediate.v_dense.weight', 'encoder.layer.23.intermediate.v_dense.bias', 'encoder.layer.23.output.v_dense.weight', 'encoder.layer.23.output.v_dense.bias', 'encoder.layer.23.output.v_LayerNorm.weight', 'encoder.layer.23.output.v_LayerNorm.bias', 'encoder.layer.24.attention_self.query.weight', 'encoder.layer.24.attention_self.query.bias', 'encoder.layer.24.attention_self.key.weight', 'encoder.layer.24.attention_self.key.bias', 'encoder.layer.24.attention_self.value.weight', 'encoder.layer.24.attention_self.value.bias', 'encoder.layer.24.attention_self.v_query.weight', 'encoder.layer.24.attention_self.v_query.bias', 'encoder.layer.24.attention_self.v_key.weight', 'encoder.layer.24.attention_self.v_key.bias', 'encoder.layer.24.attention_self.v_value.weight', 'encoder.layer.24.attention_self.v_value.bias', 'encoder.layer.24.attention_output.dense.weight', 'encoder.layer.24.attention_output.dense.bias', 'encoder.layer.24.attention_output.LayerNorm.weight', 'encoder.layer.24.attention_output.LayerNorm.bias', 'encoder.layer.24.attention_output.v_dense.weight', 'encoder.layer.24.attention_output.v_dense.bias', 'encoder.layer.24.attention_output.v_LayerNorm.weight', 'encoder.layer.24.attention_output.v_LayerNorm.bias', 'encoder.layer.25.attention_self.v_query.weight', 'encoder.layer.25.attention_self.v_query.bias', 'encoder.layer.25.attention_self.v_key.weight', 'encoder.layer.25.attention_self.v_key.bias', 'encoder.layer.25.attention_self.v_value.weight', 'encoder.layer.25.attention_self.v_value.bias', 'encoder.layer.25.attention_output.v_dense.weight', 'encoder.layer.25.attention_output.v_dense.bias', 'encoder.layer.25.attention_output.v_LayerNorm.weight', 'encoder.layer.25.attention_output.v_LayerNorm.bias', 'encoder.layer.26.intermediate.v_dense.weight', 'encoder.layer.26.intermediate.v_dense.bias', 'encoder.layer.26.output.v_dense.weight', 'encoder.layer.26.output.v_dense.bias', 'encoder.layer.26.output.v_LayerNorm.weight', 'encoder.layer.26.output.v_LayerNorm.bias', 'encoder.layer.27.attention_self.query.weight', 'encoder.layer.27.attention_self.query.bias', 'encoder.layer.27.attention_self.key.weight', 'encoder.layer.27.attention_self.key.bias', 'encoder.layer.27.attention_self.value.weight', 'encoder.layer.27.attention_self.value.bias', 'encoder.layer.27.attention_self.v_query.weight', 'encoder.layer.27.attention_self.v_query.bias', 'encoder.layer.27.attention_self.v_key.weight', 'encoder.layer.27.attention_self.v_key.bias', 'encoder.layer.27.attention_self.v_value.weight', 'encoder.layer.27.attention_self.v_value.bias', 'encoder.layer.27.attention_output.dense.weight', 'encoder.layer.27.attention_output.dense.bias', 'encoder.layer.27.attention_output.LayerNorm.weight', 'encoder.layer.27.attention_output.LayerNorm.bias', 'encoder.layer.27.attention_output.v_dense.weight', 'encoder.layer.27.attention_output.v_dense.bias', 'encoder.layer.27.attention_output.v_LayerNorm.weight', 'encoder.layer.27.attention_output.v_LayerNorm.bias', 'encoder.layer.28.attention_self.query.weight', 'encoder.layer.28.attention_self.query.bias', 'encoder.layer.28.attention_self.key.weight', 'encoder.layer.28.attention_self.key.bias', 'encoder.layer.28.attention_self.value.weight', 'encoder.layer.28.attention_self.value.bias', 'encoder.layer.28.attention_self.v_query.weight', 'encoder.layer.28.attention_self.v_query.bias', 'encoder.layer.28.attention_self.v_key.weight', 'encoder.layer.28.attention_self.v_key.bias', 'encoder.layer.28.attention_self.v_value.weight', 'encoder.layer.28.attention_self.v_value.bias', 'encoder.layer.28.attention_output.dense.weight', 'encoder.layer.28.attention_output.dense.bias', 'encoder.layer.28.attention_output.LayerNorm.weight', 'encoder.layer.28.attention_output.LayerNorm.bias', 'encoder.layer.28.attention_output.v_dense.weight', 'encoder.layer.28.attention_output.v_dense.bias', 'encoder.layer.28.attention_output.v_LayerNorm.weight', 'encoder.layer.28.attention_output.v_LayerNorm.bias', 'encoder.layer.29.intermediate.dense.weight', 'encoder.layer.29.intermediate.dense.bias', 'encoder.layer.29.intermediate.v_dense.weight', 'encoder.layer.29.intermediate.v_dense.bias', 'encoder.layer.29.output.dense.weight', 'encoder.layer.29.output.dense.bias', 'encoder.layer.29.output.LayerNorm.weight', 'encoder.layer.29.output.LayerNorm.bias', 'encoder.layer.29.output.v_dense.weight', 'encoder.layer.29.output.v_dense.bias', 'encoder.layer.29.output.v_LayerNorm.weight', 'encoder.layer.29.output.v_LayerNorm.bias', 'encoder.layer.30.attention_self.query.weight', 'encoder.layer.30.attention_self.query.bias', 'encoder.layer.30.attention_self.key.weight', 'encoder.layer.30.attention_self.key.bias', 'encoder.layer.30.attention_self.value.weight', 'encoder.layer.30.attention_self.value.bias', 'encoder.layer.30.attention_self.v_query.weight', 'encoder.layer.30.attention_self.v_query.bias', 'encoder.layer.30.attention_self.v_key.weight', 'encoder.layer.30.attention_self.v_key.bias', 'encoder.layer.30.attention_self.v_value.weight', 'encoder.layer.30.attention_self.v_value.bias', 'encoder.layer.30.attention_output.dense.weight', 'encoder.layer.30.attention_output.dense.bias', 'encoder.layer.30.attention_output.LayerNorm.weight', 'encoder.layer.30.attention_output.LayerNorm.bias', 'encoder.layer.30.attention_output.v_dense.weight', 'encoder.layer.30.attention_output.v_dense.bias', 'encoder.layer.30.attention_output.v_LayerNorm.weight', 'encoder.layer.30.attention_output.v_LayerNorm.bias', 'encoder.layer.31.attention_self.query.weight', 'encoder.layer.31.attention_self.query.bias', 'encoder.layer.31.attention_self.key.weight', 'encoder.layer.31.attention_self.key.bias', 'encoder.layer.31.attention_self.value.weight', 'encoder.layer.31.attention_self.value.bias', 'encoder.layer.31.attention_self.v_query.weight', 'encoder.layer.31.attention_self.v_query.bias', 'encoder.layer.31.attention_self.v_key.weight', 'encoder.layer.31.attention_self.v_key.bias', 'encoder.layer.31.attention_self.v_value.weight', 'encoder.layer.31.attention_self.v_value.bias', 'encoder.layer.31.attention_output.dense.weight', 'encoder.layer.31.attention_output.dense.bias', 'encoder.layer.31.attention_output.LayerNorm.weight', 'encoder.layer.31.attention_output.LayerNorm.bias', 'encoder.layer.31.attention_output.v_dense.weight', 'encoder.layer.31.attention_output.v_dense.bias', 'encoder.layer.31.attention_output.v_LayerNorm.weight', 'encoder.layer.31.attention_output.v_LayerNorm.bias', 'encoder.layer.32.intermediate.dense.weight', 'encoder.layer.32.intermediate.dense.bias', 'encoder.layer.32.intermediate.v_dense.weight', 'encoder.layer.32.intermediate.v_dense.bias', 'encoder.layer.32.output.dense.weight', 'encoder.layer.32.output.dense.bias', 'encoder.layer.32.output.LayerNorm.weight', 'encoder.layer.32.output.LayerNorm.bias', 'encoder.layer.32.output.v_dense.weight', 'encoder.layer.32.output.v_dense.bias', 'encoder.layer.32.output.v_LayerNorm.weight', 'encoder.layer.32.output.v_LayerNorm.bias', 't_pooler.dense.weight', 't_pooler.dense.bias', 'v_pooler.dense.weight', 'v_pooler.dense.bias']\n",
      "Weights from pretrained model not used in VoltaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    print('compile', target)\n",
    "    compile_model(dummy_imgfeats=dummy_imgfeats, **target)\n",
    "    print('reinit', target)\n",
    "    make_reinit_model(target['output_path'], target['output_path']+'_reinit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
